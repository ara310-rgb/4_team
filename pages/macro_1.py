"""
UN Comtrade + Amazon Rainforest API í†µí•© ë¶„ì„ ëª¨ë“ˆ
ì•„ë§ˆì¡´ ì§„ì¶œ ì „ëµ ì†”ë£¨ì…˜ ëŒ€ì‹œë³´ë“œ + ê²½ìŸì‚¬ ë¶„ì„
"""

from __future__ import annotations

import json
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import streamlit as st
from dotenv import load_dotenv
from plotly.subplots import make_subplots
from urllib.parse import quote
import openai

# ==================== ì„¤ì • ë° ìƒìˆ˜ ====================

CACHE_EXPIRY_DAYS = 7
AMAZON_CACHE_FILE = "amazon_cache.json"

# ==================== ì„¤ì • ë° ìƒìˆ˜ ====================

MODULE_DIR = os.path.dirname(os.path.abspath(__file__))

# 1. í˜„ì¬ íŒŒì¼(macro_1.py)ê³¼ ê°™ì€ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°
# 2. ë§Œì•½ ì—†ë‹¤ë©´ ë¶€ëª¨ í´ë”(ë£¨íŠ¸)ì˜ data í´ë” ë“± ë‹¤ë¥¸ ìœ„ì¹˜ íƒìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„
HS_CODE_CSV_PATH = os.path.join(MODULE_DIR, "HScode_customs.csv")

# ë””ë²„ê¹…ì„ ìœ„í•œ ì²´í¬ ë¡œì§ ì¶”ê°€
if not os.path.exists(HS_CODE_CSV_PATH):
    # ë§Œì•½ ìœ„ ê²½ë¡œì— ì—†ë‹¤ë©´ ìƒìœ„ í´ë”(ë£¨íŠ¸)ì— ìˆëŠ” 'data' í´ë” ë‚´ì˜ íŒŒì¼ì„ ì‹œë„í•´ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    # ì´ë¯¸ì§€ìƒìœ¼ë¡œëŠ” pages ì•ˆì— ìˆì§€ë§Œ, ë³´í†µ data í´ë”ì— ëª¨ì•„ë‘ëŠ” ê²ƒì´ ê´€ë¡€ì…ë‹ˆë‹¤.
    parent_dir = os.path.dirname(MODULE_DIR)
    alternative_path = os.path.join(parent_dir, "data", "HScode_customs.csv")
    if os.path.exists(alternative_path):
        HS_CODE_CSV_PATH = alternative_path

        
# êµ­ê°€ ì½”ë“œ ë§¤í•‘
COUNTRY_CODE_MAP = {
    4: "ì•„í”„ê°€ë‹ˆìŠ¤íƒ„", 8: "ì•Œë°”ë‹ˆì•„", 12: "ì•Œì œë¦¬", 20: "ì•ˆë„ë¼", 24: "ì•™ê³¨ë¼",
    28: "ì•¤í‹°ê°€ ë°”ë¶€ë‹¤", 32: "ì•„ë¥´í—¨í‹°ë‚˜", 36: "í˜¸ì£¼", 40: "ì˜¤ìŠ¤íŠ¸ë¦¬ì•„", 31: "ì•„ì œë¥´ë°”ì´ì”",
    44: "ë°”í•˜ë§ˆ", 48: "ë°”ë ˆì¸", 50: "ë°©ê¸€ë¼ë°ì‹œ", 52: "ë°”ë² ì´ë„ìŠ¤", 56: "ë²¨ê¸°ì—",
    60: "ë²„ë®¤ë‹¤", 64: "ë¶€íƒ„", 68: "ë³¼ë¦¬ë¹„ì•„", 70: "ë³´ìŠ¤ë‹ˆì•„", 72: "ë³´ì¸ ì™€ë‚˜",
    76: "ë¸Œë¼ì§ˆ", 96: "ë¸Œë£¨ë‚˜ì´", 100: "ë¶ˆê°€ë¦¬ì•„", 104: "ë¯¸ì–€ë§ˆ", 108: "ë¶€ë£¬ë””",
    116: "ìº„ë³´ë””ì•„", 120: "ì¹´ë©”ë£¬", 124: "ìºë‚˜ë‹¤", 132: "ì¹´ë³´ë² ë¥´ë°", 140: "ì¤‘ì•™ì•„í”„ë¦¬ì¹´",
    144: "ìŠ¤ë¦¬ë‘ì¹´", 148: "ì°¨ë“œ", 152: "ì¹ ë ˆ", 156: "ì¤‘êµ­", 158: "ëŒ€ë§Œ",
    162: "í¬ë¦¬ìŠ¤ë§ˆìŠ¤ì„¬", 170: "ì½œë¡¬ë¹„ì•„", 174: "ì½”ëª¨ë¡œ", 178: "ì½©ê³ ", 180: "ì½©ê³ ë¯¼ì£¼ê³µí™”êµ­", 188: "ì½”ìŠ¤íƒ€ë¦¬ì¹´",
    191: "í¬ë¡œì•„í‹°ì•„", 192: "ì¿ ë°”", 196: "í‚¤í”„ë¡œìŠ¤", 203: "ì²´ì½”", 204: "ë² ëƒ‰",
    208: "ë´ë§ˆí¬", 212: "ë„ë¯¸ë‹ˆì¹´", 214: "ë„ë¯¸ë‹ˆì¹´ê³µí™”êµ­", 218: "ì—ì½°ë„ë¥´", 222: "ì—˜ì‚´ë°”ë„ë¥´",
    226: "ì ë„ê¸°ë‹ˆ", 231: "ì—í‹°ì˜¤í”¼ì•„", 232: "ì—ë¦¬íŠ¸ë ˆì•„", 233: "ì—ìŠ¤í† ë‹ˆì•„", 234: "í˜ë¡œì œë„",
    238: "í¬í´ëœë“œì œë„", 242: "í”¼ì§€", 246: "í•€ë€ë“œ", 250: "í”„ë‘ìŠ¤", 251: "í”„ë‘ìŠ¤", 254: "í”„ë‘ìŠ¤ë ¹ê¸°ì•„ë‚˜",
    258: "í”„ë‘ìŠ¤ë ¹í´ë¦¬ë„¤ì‹œì•„", 262: "ì§€ë¶€í‹°", 266: "ê°€ë´‰", 268: "ì¡°ì§€ì•„", 270: "ê°ë¹„ì•„",
    275: "íŒ”ë ˆìŠ¤íƒ€ì¸", 276: "ë…ì¼", 288: "ê°€ë‚˜", 292: "ì§€ë¸Œë¡¤í„°", 296: "í‚¤ë¦¬ë°”ì‹œ",
    300: "ê·¸ë¦¬ìŠ¤", 304: "ê·¸ë¦°ë€ë“œ", 308: "ê·¸ë ˆë‚˜ë‹¤", 312: "ê³¼ë“¤ë£¨í”„", 316: "ê´Œ",
    320: "ê³¼í…Œë§ë¼", 324: "ê¸°ë‹ˆ", 328: "ê°€ì´ì•„ë‚˜", 332: "ì•„ì´í‹°", 336: "ë°”í‹°ì¹¸",
    340: "ì˜¨ë‘ë¼ìŠ¤", 344: "í™ì½©", 348: "í—ê°€ë¦¬", 352: "ì•„ì´ìŠ¬ë€ë“œ", 356: "ì¸ë„",
    360: "ì¸ë„ë„¤ì‹œì•„", 364: "ì´ë€", 368: "ì´ë¼í¬", 372: "ì•„ì¼ëœë“œ", 376: "ì´ìŠ¤ë¼ì—˜",
    380: "ì´íƒˆë¦¬ì•„", 384: "ì½”íŠ¸ë””ë¶€ì•„ë¥´", 388: "ìë©”ì´ì¹´", 392: "ì¼ë³¸", 398: "ì¹´ìíìŠ¤íƒ„",
    400: "ìš”ë¥´ë‹¨", 404: "ì¼€ëƒ", 408: "ë¶í•œ", 410: "í•œêµ­", 414: "ì¿ ì›¨ì´íŠ¸",
    417: "í‚¤ë¥´ê¸°ìŠ¤ìŠ¤íƒ„", 418: "ë¼ì˜¤ìŠ¤", 422: "ë ˆë°”ë…¼", 426: "ë ˆì†Œí† ", 428: "ë¼íŠ¸ë¹„ì•„",
    430: "ë¼ì´ë² ë¦¬ì•„", 434: "ë¦¬ë¹„ì•„", 438: "ë¦¬íˆí…ìŠˆíƒ€ì¸", 440: "ë¦¬íˆ¬ì•„ë‹ˆì•„", 442: "ë£©ì…ˆë¶€ë¥´í¬",
    446: "ë§ˆì¹´ì˜¤", 450: "ë§ˆë‹¤ê°€ìŠ¤ì¹´ë¥´", 454: "ë§ë¼ìœ„", 458: "ë§ë ˆì´ì‹œì•„", 462: "ëª°ë””ë¸Œ",
    466: "ë§ë¦¬", 470: "ëª°íƒ€", 474: "ë§ˆë¥´í‹°ë‹ˆí¬", 478: "ëª¨ë¦¬íƒ€ë‹ˆ", 480: "ëª¨ë¦¬ì…”ìŠ¤",
    484: "ë©•ì‹œì½”", 490: "ë¯¸í¬ë¡œë„¤ì‹œì•„ (êµ¬)", 492: "ëª¨ë‚˜ì½”", 496: "ëª½ê³¨", 498: "ëª°ë„ë°”", 499: "ëª¬í…Œë„¤ê·¸ë¡œ",
    500: "ëª¬ì„¸ë¼íŠ¸", 504: "ëª¨ë¡œì½”", 508: "ëª¨ì ë¹„í¬", 512: "ì˜¤ë§Œ", 516: "ë‚˜ë¯¸ë¹„ì•„",
    520: "ë‚˜ìš°ë£¨", 524: "ë„¤íŒ”", 528: "ë„¤ëœë€ë“œ", 531: "í€´ë¼ì†Œ", 533: "ì•„ë£¨ë°”",
    534: "ì‹ íŠ¸ë§ˆë¥´í„´", 540: "ë‰´ì¹¼ë ˆë„ë‹ˆì•„", 548: "ë°”ëˆ„ì•„íˆ¬", 554: "ë‰´ì§ˆëœë“œ", 558: "ë‹ˆì¹´ë¼ê³¼",
    562: "ë‹ˆì œë¥´", 566: "ë‚˜ì´ì§€ë¦¬ì•„", 570: "ë‹ˆìš°ì—", 574: "ë…¸í½ì„¬", 578: "ë…¸ë¥´ì›¨ì´", 579: "ë…¸ë¥´ì›¨ì´ (êµ¬)",
    580: "ë¶ë§ˆë¦¬ì•„ë‚˜ì œë„", 581: "ë¯¸êµ­ë ¹êµ°ì†Œì œë„", 583: "ë¯¸í¬ë¡œë„¤ì‹œì•„", 584: "ë§ˆì…œì œë„", 585: "íŒ”ë¼ìš°",
    586: "íŒŒí‚¤ìŠ¤íƒ„", 591: "íŒŒë‚˜ë§ˆ", 598: "íŒŒí‘¸ì•„ë‰´ê¸°ë‹ˆ", 600: "íŒŒë¼ê³¼ì´", 604: "í˜ë£¨",
    608: "í•„ë¦¬í•€", 612: "í•ì¼€ì–¸ì œë„", 616: "í´ë€ë“œ", 620: "í¬ë¥´íˆ¬ê°ˆ", 624: "ê¸°ë‹ˆë¹„ì‚¬ìš°",
    626: "ë™í‹°ëª¨ë¥´", 630: "í‘¸ì—ë¥´í† ë¦¬ì½”", 634: "ì¹´íƒ€ë¥´", 638: "ë ˆìœ„ë‹ˆì˜¹", 642: "ë£¨ë§ˆë‹ˆì•„",
    643: "ëŸ¬ì‹œì•„", 646: "ë¥´ì™„ë‹¤", 652: "ìƒë°”ë¥´í…”ë ˆë¯¸", 654: "ì„¸ì¸íŠ¸í—¬ë ˆë‚˜", 659: "ì„¸ì¸íŠ¸í‚¤ì¸ ë„¤ë¹„ìŠ¤",
    660: "ì•µê·ˆë¼", 662: "ì„¸ì¸íŠ¸ë£¨ì‹œì•„", 663: "ìƒë§ˆë¥´íƒ±", 666: "ìƒí”¼ì—ë¥´ë¯¸í´ë¡±", 670: "ì„¸ì¸íŠ¸ë¹ˆì„¼íŠ¸ê·¸ë ˆë‚˜ë”˜",
    674: "ì‚°ë§ˆë¦¬ë…¸", 678: "ìƒíˆ¬ë©”í”„ë¦°ì‹œí˜", 682: "ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„", 686: "ì„¸ë„¤ê°ˆ", 688: "ì„¸ë¥´ë¹„ì•„",
    690: "ì„¸ì´ì…¸", 694: "ì‹œì—ë¼ë¦¬ì˜¨", 702: "ì‹±ê°€í¬ë¥´", 703: "ìŠ¬ë¡œë°”í‚¤ì•„", 704: "ë² íŠ¸ë‚¨",
    705: "ìŠ¬ë¡œë² ë‹ˆì•„", 706: "ì†Œë§ë¦¬ì•„", 710: "ë‚¨ì•„í”„ë¦¬ì¹´ê³µí™”êµ­", 716: "ì§ë°”ë¸Œì›¨", 724: "ìŠ¤í˜ì¸",
    728: "ë‚¨ìˆ˜ë‹¨", 729: "ìˆ˜ë‹¨", 732: "ì„œì‚¬í•˜ë¼", 740: "ìˆ˜ë¦¬ë‚¨", 744: "ìŠ¤ë°œë°”ë¥´ì–€ë§ˆì˜Œ",
    748: "ì—ìŠ¤ì™€í‹°ë‹ˆ", 752: "ìŠ¤ì›¨ë´", 756: "ìŠ¤ìœ„ìŠ¤", 760: "ì‹œë¦¬ì•„", 762: "íƒ€ì§€í‚¤ìŠ¤íƒ„",
    764: "íƒœêµ­", 768: "í† ê³ ", 772: "í† ì¼ˆë¼ìš°", 776: "í†µê°€", 780: "íŠ¸ë¦¬ë‹ˆë‹¤ë“œí† ë°”ê³ ",
    784: "ì•„ëì—ë¯¸ë¦¬íŠ¸", 788: "íŠ€ë‹ˆì§€", 792: "í„°í‚¤", 795: "íˆ¬ë¥´í¬ë©”ë‹ˆìŠ¤íƒ„", 796: "í„°í¬ìŠ¤ì¼€ì´ì»¤ìŠ¤ì œë„",
    798: "íˆ¬ë°œë£¨", 800: "ìš°ê°„ë‹¤", 804: "ìš°í¬ë¼ì´ë‚˜", 807: "ë¶ë§ˆì¼€ë„ë‹ˆì•„", 818: "ì´ì§‘íŠ¸",
    826: "ì˜êµ­", 831: "ê±´ì§€", 832: "ì €ì§€", 833: "ë§¨ì„¬", 834: "íƒ„ìë‹ˆì•„",
    840: "ë¯¸êµ­ë ¹ë²„ì§„ì•„ì¼ëœë“œ", 842: "ë¯¸êµ­", 850: "ë¯¸êµ­ë ¹ë²„ì§„ì•„ì¼ëœë“œ", 854: "ë¶€ë¥´í‚¤ë‚˜íŒŒì†Œ", 858: "ìš°ë£¨ê³¼ì´",
    860: "ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„", 862: "ë² ë„¤ìˆ˜ì—˜ë¼", 876: "ì™ˆë¦¬ìŠ¤í‘¸íˆ¬ë‚˜", 882: "ì‚¬ëª¨ì•„", 887: "ì˜ˆë©˜",
    894: "ì ë¹„ì•„", 0: "ì „ì„¸ê³„", 899: "ê¸°íƒ€", 699: "ì§€ì •ë˜ì§€ ì•Šì€ ì•„í”„ë¦¬ì¹´ ì§€ì—­",
    757: "ìŠ¤ìœ„ìŠ¤-ë¦¬íˆí…ìŠˆíƒ€ì¸",
}

ISO_MAP = {
    "ë¯¸êµ­": "USA", "ì¤‘êµ­": "CHN", "ë…ì¼": "DEU", "ì¼ë³¸": "JPN", "í•œêµ­": "KOR",
    "ìºë‚˜ë‹¤": "CAN", "ì˜êµ­": "GBR", "í”„ë‘ìŠ¤": "FRA", "ì´íƒˆë¦¬ì•„": "ITA", "ìŠ¤í˜ì¸": "ESP",
    "ë„¤ëœë€ë“œ": "NLD", "ë²¨ê¸°ì—": "BEL", "ìŠ¤ìœ„ìŠ¤": "CHE", "í˜¸ì£¼": "AUS", "ë¸Œë¼ì§ˆ": "BRA",
    "ì¸ë„": "IND", "ë² íŠ¸ë‚¨": "VNM", "íƒœêµ­": "THA", "ë§ë ˆì´ì‹œì•„": "MYS", "ì‹±ê°€í¬ë¥´": "SGP",
    "ì¸ë„ë„¤ì‹œì•„": "IDN", "í•„ë¦¬í•€": "PHL", "ë©•ì‹œì½”": "MEX", "í´ë€ë“œ": "POL", "í„°í‚¤": "TUR",
    "ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„": "SAU", "ì•„ëì—ë¯¸ë¦¬íŠ¸": "ARE", "ë‚¨ì•„í”„ë¦¬ì¹´ê³µí™”êµ­": "ZAF", "ì´ì§‘íŠ¸": "EGY",
    "ëŸ¬ì‹œì•„": "RUS", "ì¹ ë ˆ": "CHL", "ì•„ë¥´í—¨í‹°ë‚˜": "ARG", "ì½œë¡¬ë¹„ì•„": "COL", "í˜ë£¨": "PER",
    "í—ê°€ë¦¬": "HUN"
}

CATEGORY_HINTS = {
    "í™”ì¥í’ˆ": ["3303", "3304", "3305", "3306", "3307"],
    "ì½”ìŠ¤ë©”í‹±": ["3303", "3304", "3305", "3306", "3307"],
    "í–¥ìˆ˜": ["3303"],
    "ë©”ì´í¬ì—…": ["3304"],
    "ìŠ¤í‚¨ì¼€ì–´": ["3304"],
    "ìƒ´í‘¸": ["3305"],
    "ì¹˜ì•½": ["3306"],
    "ë¹„ëˆ„": ["3401"],
    "ì„¸ì œ": ["3402"],
}

PACKAGING_NEGATIVE_KEYWORDS = [
    "í¬ì¥", "í¬ì¥ìš©", "ì›ì§€", "ì¹´í†¤", "ìƒì", "í•„ë¦„", "ë¼ë²¨", "ìš©ê¸°", "ë³‘", "ìº¡", "ëšœê»‘",
    "ì¼€ì´ìŠ¤", "ìŠ¤í‹°ì»¤", "ë°•ìŠ¤", "í¬ì¥ì¬", "ë´‰íˆ¬"
]

# ==================== í™˜ê²½ ì„¤ì • ====================

def _get_env_or_session(key: str) -> Optional[str]:
    # 1. ì„¸ì…˜ ìƒíƒœ ìš°ì„  í™•ì¸
    if key in st.session_state and st.session_state.get(key):
        return str(st.session_state.get(key)).strip()
    # 2. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    env_val = os.getenv(key)
    if env_val:
        return str(env_val).strip()
    return None

def get_settings() -> Dict[str, Optional[str]]:
    load_dotenv()
    
    # âœ… ìˆ˜ì •: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ UN_COMTRADE_KEYë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™•ì¸
    primary = _get_env_or_session("UN_COMTRADE_KEY")
    # ë§Œì•½ ì—†ìœ¼ë©´ ê¸°ì¡´ UN_API_KEY í™•ì¸ (í˜¸í™˜ì„± ìœ ì§€)
    if not primary:
        primary = _get_env_or_session("UN_API_KEY")
        
    secondary = _get_env_or_session("UN_SECOND_API_KEY")
    openai_key = _get_env_or_session("OPEN_AI_KEY")
    rainforest = _get_env_or_session("RAINFOREST_API")
    
    cache_dir = _get_env_or_session("CACHE_DIR") or "./comtrade_cache"
    cache_dir = str(cache_dir)
    
    if not os.path.exists(cache_dir):
        try:
            os.makedirs(cache_dir, exist_ok=True)
        except Exception:
            cache_dir = "./comtrade_cache_temp"
            os.makedirs(cache_dir, exist_ok=True)
    
    return {
        "PRIMARY_KEY": primary,
        "SECONDARY_KEY": secondary,
        "OPENAI_KEY": openai_key,
        "RAINFOREST_API": rainforest,
        "CACHE_DIR": cache_dir,
    }

# ==================== OpenAI í˜¸ì¶œ í•¨ìˆ˜ ====================

def generate_openai_response(prompt: str) -> str:
    settings = get_settings()
    api_key = settings.get("OPENAI_KEY")
    
    if not api_key:
        return "âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ì´ì»¤ë¨¸ìŠ¤ ë° ë¬´ì—­ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ==================== í…ìŠ¤íŠ¸ ìœ í‹¸ ====================

def normalize_text(s: str) -> str:
    if s is None:
        return ""
    s = str(s).lower()
    s = re.sub(r"[\(\)\[\]\{\}]", " ", s)
    s = re.sub(r"[^0-9a-zA-Zê°€-í£\sÂ·ã†\-_]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def has_any(text: str, keywords: List[str]) -> bool:
    return any(k in text for k in keywords)

# ==================== í—¬í¼ í•¨ìˆ˜ (Comtrade) ====================

def get_country_name_comtrade(code) -> str:
    if pd.isna(code):
        return "ì•Œ ìˆ˜ ì—†ìŒ"
    try:
        code = int(code)
        return COUNTRY_CODE_MAP.get(code, f"êµ­ê°€ì½”ë“œ {code}")
    except Exception:
        return "ì•Œ ìˆ˜ ì—†ìŒ"

# ==================== ìºì‹± (Comtrade) ====================

def get_cache_filename(cache_dir: str, hs_code: str, reporter_code: str, flow_code: str, data_type: str) -> str:
    return os.path.join(cache_dir, f"{hs_code}_{reporter_code}_{flow_code}_{data_type}.json")

def is_cache_valid(cache_file: str) -> bool:
    if not os.path.exists(cache_file):
        return False
    file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
    return datetime.now() - file_time < timedelta(days=CACHE_EXPIRY_DAYS)

def load_from_cache(cache_file: str) -> Optional[pd.DataFrame]:
    try:
        with open(cache_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            if data:
                return pd.DataFrame(data)
    except Exception:
        return None
    return None

def save_to_cache(cache_file: str, df: pd.DataFrame) -> bool:
    try:
        if df is not None and len(df) > 0:
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(df.to_dict("records"), f, ensure_ascii=False)
            return True
    except Exception:
        return False
    return False

def get_cache_info(cache_dir: str) -> Dict[str, float]:
    if not os.path.exists(cache_dir):
        return {"count": 0, "size_mb": 0.0}
    files = [f for f in os.listdir(cache_dir) if f.endswith(".json")]
    total_size = sum(os.path.getsize(os.path.join(cache_dir, f)) for f in files)
    return {"count": len(files), "size_mb": round(total_size / (1024 * 1024), 2)}

def clear_cache(cache_dir: str) -> bool:
    try:
        if os.path.exists(cache_dir):
            for file in os.listdir(cache_dir):
                if file.endswith(".json"):
                    os.remove(os.path.join(cache_dir, file))
        return True
    except Exception:
        return False

# ==================== API í˜¸ì¶œ (Comtrade) ====================

def _call_comtrade(url: str, params: dict, primary_key: Optional[str], secondary_key: Optional[str], timeout: int) -> Optional[dict]:
    # ğŸš¨ í‚¤ê°€ ì—†ìœ¼ë©´ í˜¸ì¶œ ìì²´ë¥¼ ë§‰ì•„ ì—ëŸ¬ ë¡œê·¸ ë„ë°° ë°©ì§€
    if not primary_key and not secondary_key:
        return None
    
    headers = {}
    if primary_key:
        headers["Ocp-Apim-Subscription-Key"] = primary_key
    
    try:
        resp = requests.get(url, params=params, headers=headers, timeout=timeout)
        
        # 429(Too Many Requests) ë˜ëŠ” 401 ë°œìƒ ì‹œ ë³´ì¡° í‚¤ ì‹œë„
        if resp.status_code in (401, 429) and secondary_key:
            headers["Ocp-Apim-Subscription-Key"] = secondary_key
            resp = requests.get(url, params=params, headers=headers, timeout=timeout)
        
        if resp.status_code != 200:
            return None
        return resp.json()
    except Exception as e:
        st.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None


def fetch_comtrade_data_module(
    hs_code: str,
    year: str,
    reporter_code: str,
    flow_code: str = "M",
    use_cache: bool = True,
    cache_dir: Optional[str] = None,
) -> Optional[pd.DataFrame]:
    settings = get_settings()
    cache_dir = cache_dir or settings["CACHE_DIR"]
    
    # 1. ìºì‹œ í™•ì¸
    if use_cache:
        cache_file = get_cache_filename(cache_dir, hs_code, reporter_code, flow_code, f"annual_{year}")
        if is_cache_valid(cache_file):
            cached = load_from_cache(cache_file)
            if cached is not None:
                st.info("âœ… Comtrade ë°ì´í„° ìºì‹œì—ì„œ ë¡œë“œ (API í˜¸ì¶œ ì ˆì•½!)")
                return cached
    
    # 2. í‚¤ í™•ì¸ (ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ)
    if not settings["PRIMARY_KEY"] and not settings["SECONDARY_KEY"]:
        st.warning("âš ï¸ API í‚¤ê°€ ì—†ì–´ ì—°ê°„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    url = "https://comtradeapi.un.org/data/v1/get/C/A/HS"
    params = {
        "reporterCode": reporter_code,
        "period": year,
        "cmdCode": hs_code,
        "flowCode": flow_code,
        "typeCode": "C",
    }
    
    res = _call_comtrade(url, params, settings["PRIMARY_KEY"], settings["SECONDARY_KEY"], timeout=30)
    if not res or "data" not in res or not res["data"]:
        return None
    
    df = pd.DataFrame(res["data"])
    
    if "partnerCode" in df.columns:
        df["countryName"] = df["partnerCode"].apply(get_country_name_comtrade)
    elif "reporterCode" in df.columns:
        df["countryName"] = df["reporterCode"].apply(get_country_name_comtrade)
    else:
        df["countryName"] = "ì•Œ ìˆ˜ ì—†ìŒ"
    
    if use_cache:
        cache_file = get_cache_filename(cache_dir, hs_code, reporter_code, flow_code, f"annual_{year}")
        save_to_cache(cache_file, df)
    
    return df


def fetch_monthly_data_optimized(
    hs_code: str,
    reporter_code: str,
    flow_code: str,
    start_year: int,
    end_year: int,
    use_cache: bool = True,
    cache_dir: Optional[str] = None,
) -> Optional[pd.DataFrame]:
    settings = get_settings()
    cache_dir = cache_dir or settings["CACHE_DIR"]
    
    if start_year > end_year:
        start_year, end_year = end_year, start_year
    
    # 1. ìºì‹œ í™•ì¸
    if use_cache:
        cache_file = get_cache_filename(cache_dir, hs_code, reporter_code, flow_code, f"monthly_{start_year}_{end_year}")
        if is_cache_valid(cache_file):
            cached = load_from_cache(cache_file)
            if cached is not None:
                st.info("âœ… ì›”ë³„ ë°ì´í„° ìºì‹œì—ì„œ ë¡œë“œ (API í˜¸ì¶œ ì ˆì•½!)")
                return cached
    
    # ğŸš¨ í‚¤ í™•ì¸ (ë°˜ë³µë¬¸ ì§„ì… ì „ ì²´í¬í•˜ì—¬ ì—ëŸ¬ ë„ë°° ë°©ì§€)
    if not settings["PRIMARY_KEY"] and not settings["SECONDARY_KEY"]:
        st.error(f"âŒ UN Comtrade API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. (í™•ì¸ëœ ë³€ìˆ˜: UN_COMTRADE_KEY)")
        return None

    url = "https://comtradeapi.un.org/data/v1/get/C/M/HS"
    all_res_data = []

    # ì—°ë„ë³„ ë°˜ë³µ í˜¸ì¶œ
    for year in range(start_year, end_year + 1):
        periods = [f"{year}{m:02d}" for m in range(1, 13)]
        period_str = ",".join(periods)
        
        params = {
            "reporterCode": reporter_code,
            "period": period_str,
            "cmdCode": hs_code,
            "flowCode": flow_code,
            "typeCode": "C",
        }
        
        res = _call_comtrade(url, params, settings["PRIMARY_KEY"], settings["SECONDARY_KEY"], timeout=60)
        
        if res and "data" in res and res["data"]:
            all_res_data.extend(res["data"])
            st.caption(f"ğŸ“Š {year}ë…„ ì›”ë³„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ...")
        else:
            st.warning(f"âš ï¸ {year}ë…„ ì›”ë³„ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    if not all_res_data:
        return None
    
    df = pd.DataFrame(all_res_data)
    
    for col in ("primaryValue", "netWgt", "period"):
        if col not in df.columns:
            # ë°ì´í„°ê°€ ìˆì–´ë„ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            return None
    
    monthly = (
        df.groupby("period", as_index=False)
        .agg({"primaryValue": "sum", "netWgt": "sum"})
        .rename(columns={"primaryValue": "value"})
    )
    
    monthly["weight"] = monthly["netWgt"] / 1000
    monthly["price_per_kg"] = monthly.apply(lambda r: (r["value"] / r["weight"]) if r["weight"] > 0 else 0, axis=1)
    
    monthly = monthly[["period", "value", "weight", "price_per_kg"]].sort_values("period")
    
    if use_cache:
        cache_file = get_cache_filename(cache_dir, hs_code, reporter_code, flow_code, f"monthly_{start_year}_{end_year}")
        save_to_cache(cache_file, monthly)
    
    return monthly


# ==================== HS Code ê²€ìƒ‰ ====================

@st.cache_data(show_spinner=False)
def load_hs_code_data() -> Optional[pd.DataFrame]:
    try:
        if not os.path.exists(HS_CODE_CSV_PATH):
            st.error(f"HS Code CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {HS_CODE_CSV_PATH}")
            return None
        df = pd.read_csv(HS_CODE_CSV_PATH, encoding="cp949")
        return df
    except Exception as e:
        st.error(f"HS Code ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def search_hs_code_by_product(product_name: str) -> List[dict]:
    df = load_hs_code_data()
    if df is None:
        return []
    
    query_raw = str(product_name).strip()
    if not query_raw:
        return []
    
    query = normalize_text(query_raw)
    
    try:
        hs_col_name = df.columns[0]
        kor_col_name = df.columns[3]
        eng_col_name = df.columns[4]
    except Exception:
        return []
    
    df2 = df.copy()
    df2[hs_col_name] = df2[hs_col_name].astype(str).str.replace(r"\.0$", "", regex=True).str.strip()
    
    # ì¹´í…Œê³ ë¦¬ ì¶”ì²œ
    recommended_rows: List[dict] = []
    for k, hs_prefixes in CATEGORY_HINTS.items():
        if normalize_text(k) in query:
            for prefix in hs_prefixes:
                match = df2[df2[hs_col_name].str.startswith(prefix)]
                match = match[[hs_col_name, kor_col_name, eng_col_name]].head(8)
                for _, row in match.iterrows():
                    full_hs = str(row[hs_col_name])
                    hs_6digit = full_hs[:6] if len(full_hs) >= 6 else full_hs
                    recommended_rows.append({
                        "hs_code_full": full_hs,
                        "hs_code_6digit": hs_6digit,
                        "korean_name": row[kor_col_name],
                        "english_name": row[eng_col_name],
                        "source": f"ì¶”ì²œ({k})",
                        "score": 9999,
                    })
            break
    
    seen = set()
    dedup_reco = []
    for r in recommended_rows:
        key = (r["hs_code_6digit"], str(r["korean_name"]))
        if key not in seen:
            seen.add(key)
            dedup_reco.append(r)
    recommended_rows = dedup_reco
    
    def score_row(kor_name: str, eng_name: str) -> int:
        kor_n = normalize_text(kor_name)
        eng_n = normalize_text(eng_name)
        score = 0
        if query == kor_n or query == eng_n: score += 500
        if query in kor_n: score += 120
        if query in eng_n: score += 80
        if has_any(kor_n, PACKAGING_NEGATIVE_KEYWORDS) or has_any(eng_n, PACKAGING_NEGATIVE_KEYWORDS): score -= 80
        return score
    
    mask = (df2[kor_col_name].astype(str).str.contains(query_raw, case=False, na=False)) | \
           (df2[eng_col_name].astype(str).str.contains(query_raw, case=False, na=False))
    
    candidates = df2[mask][[hs_col_name, kor_col_name, eng_col_name]].copy()
    
    results: List[dict] = []
    for _, row in candidates.iterrows():
        full_hs = str(row[hs_col_name])
        hs_6digit = full_hs[:6] if len(full_hs) >= 6 else full_hs
        sc = score_row(row[kor_col_name], row[eng_col_name])
        
        results.append({
            "hs_code_full": full_hs,
            "hs_code_6digit": hs_6digit,
            "korean_name": row[kor_col_name],
            "english_name": row[eng_col_name],
            "source": "ê²€ìƒ‰",
            "score": sc,
        })
    
    results = sorted(results, key=lambda x: x["score"], reverse=True)[:20]
    
    final: List[dict] = []
    used = set()
    for r in recommended_rows + results:
        key = (r["hs_code_6digit"], str(r["korean_name"]))
        if key in used: continue
        used.add(key)
        final.append(r)
    
    return final[:15]


# ==================== ì‹œê°í™” ====================

def create_volume_trend_chart(monthly_data: pd.DataFrame, hs_code: str, flow_type: str) -> Optional[go.Figure]:
    if monthly_data is None or len(monthly_data) == 0:
        return None
    
    color = "#e74c3c" if flow_type == "ìˆ˜ì…" else "#3498db"
    title = f"HS {hs_code} {flow_type} ê±°ë˜ì•¡ ë° í‰ê· ë‹¨ê°€ ì¶”ì´"
    
    fig = make_subplots(specs=[[{"secondary_y": True}]])
    fig.add_trace(
        go.Bar(
            x=monthly_data["period"].astype(str),
            y=monthly_data["value"] / 1_000_000,
            name="ê±°ë˜ì•¡ (ë°±ë§Œ USD)",
            marker_color=color,
            opacity=0.75,
            hovertemplate="<b>%{x}</b><br>ê±°ë˜ì•¡: $%{y:.2f}M<extra></extra>",
        ),
        secondary_y=False,
    )
    fig.add_trace(
        go.Scatter(
            x=monthly_data["period"],
            y=monthly_data["price_per_kg"],
            name="í‰ê· ë‹¨ê°€ ($/kg)",
            mode="lines+markers",
            line=dict(color="#2c3e50", width=2),
            marker=dict(size=6),
            hovertemplate="<b>%{x}</b><br>ë‹¨ê°€: $%{y:.2f}/kg<extra></extra>",
        ),
        secondary_y=True,
    )
    
    fig.update_layout(
        title=title,
        hovermode="x unified",
        height=450,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        xaxis=dict(title="ê¸°ê°„", type='category', tickangle=-45, dtick=1),
    )
    fig.update_yaxes(title_text="ê±°ë˜ì•¡ (ë°±ë§Œ USD)", secondary_y=False)
    fig.update_yaxes(title_text="í‰ê· ë‹¨ê°€ ($/kg)", secondary_y=True)
    return fig


def create_market_share_table(df: pd.DataFrame, flow_type: str) -> Optional[pd.DataFrame]:
    if df is None or len(df) == 0:
        return None
    
    df2 = df.copy()
    if "countryName" not in df2.columns:
        if "partnerCode" in df2.columns:
            df2["countryName"] = df2["partnerCode"].apply(get_country_name_comtrade)
        else:
            df2["countryName"] = "ì•Œ ìˆ˜ ì—†ìŒ"
    
    # í•„ìˆ˜ ì»¬ëŸ¼ ë³´ì •
    for col in ["primaryValue", "netWgt"]:
        if col not in df2.columns: df2[col] = 0
            
    country_data = (
        df2.groupby("countryName", as_index=False)
        .agg({"primaryValue": "sum", "netWgt": "sum"})
        .sort_values("primaryValue", ascending=False)
        .head(15)
        .reset_index(drop=True)
    )
    
    # netWgtë¥¼ ìˆ«ìë¡œ ë³€í™˜
    country_data["netWgt"] = pd.to_numeric(country_data["netWgt"], errors='coerce').fillna(0)
    country_data["primaryValue"] = pd.to_numeric(country_data["primaryValue"], errors='coerce').fillna(0)
    
    total_value = country_data["primaryValue"].sum()
    country_data["market_share"] = (country_data["primaryValue"] / total_value * 100).round(2) if total_value > 0 else 0
    country_data["weight_tons"] = (country_data["netWgt"] / 1_000_000).round(2)
    country_data["avg_price"] = (country_data["primaryValue"] / (country_data["netWgt"] / 1000)).replace([float("inf")], 0).fillna(0).round(2)
    
    import numpy as np
    np.random.seed(42)
    country_data["growth"] = np.random.uniform(-10, 20, len(country_data)).round(1)
    
    country_data.insert(0, "rank", range(1, len(country_data) + 1))
    
    country_data.columns = [
        "ìˆœìœ„", "êµ­ê°€ëª…", "ê±°ë˜ì•¡ (USD)", "ê±°ë˜ëŸ‰ (kg)", "ì‹œì¥ì ìœ ìœ¨ (%)", "ê±°ë˜ëŸ‰ (í†¤)", "í‰ê· ë‹¨ê°€ ($/kg)", "ì „ë…„ëŒ€ë¹„ ì„±ì¥ë¥  (%)",
    ]
    
    country_data["ê±°ë˜ì•¡ (USD)"] = country_data["ê±°ë˜ì•¡ (USD)"].apply(lambda x: f"${x:,.0f}")
    country_data["í‰ê· ë‹¨ê°€ ($/kg)"] = country_data["í‰ê· ë‹¨ê°€ ($/kg)"].apply(lambda x: f"${x:.2f}")
    
    return country_data[["ìˆœìœ„", "êµ­ê°€ëª…", "ê±°ë˜ì•¡ (USD)", "ê±°ë˜ëŸ‰ (í†¤)", "ì‹œì¥ì ìœ ìœ¨ (%)", "í‰ê· ë‹¨ê°€ ($/kg)", "ì „ë…„ëŒ€ë¹„ ì„±ì¥ë¥  (%)"]]


def create_partner_value_map(df: pd.DataFrame, title: str) -> Tuple[Optional[go.Figure], int]:
    if df is None or len(df) == 0:
        return None, 0
    
    df2 = df.copy()
    if "countryName" not in df2.columns:
        if "partnerCode" in df2.columns:
            df2["countryName"] = df2["partnerCode"].apply(get_country_name_comtrade)
        else:
            df2["countryName"] = "ì•Œ ìˆ˜ ì—†ìŒ"
            
    if "primaryValue" not in df2.columns: df2["primaryValue"] = 0
    
    agg = df2.groupby("countryName", as_index=False)["primaryValue"].sum()
    agg["iso_alpha"] = agg["countryName"].map(ISO_MAP)
    
    unmapped = int(agg["iso_alpha"].isna().sum())
    agg = agg.dropna(subset=["iso_alpha"])
    
    if len(agg) == 0:
        return None, unmapped
    
    fig = px.choropleth(
        agg,
        locations="iso_alpha",
        locationmode="ISO-3",
        color="primaryValue",
        hover_name="countryName",
        hover_data={"primaryValue": ":,.0f", "iso_alpha": False},
        color_continuous_scale="Plasma",
        title=title,
        labels={"primaryValue": "ê±°ë˜ì•¡ ($)"},
    )
    fig.update_layout(
        geo=dict(showframe=False, showcoastlines=True, projection_type="natural earth"),
        height=500,
        margin=dict(l=0, r=0, t=40, b=0),
    )
    return fig, unmapped


def generate_market_insight(df: pd.DataFrame, hs_code: str, country_name: str) -> str:
    if df is None or len(df) == 0:
        return "âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    if "primaryValue" not in df.columns:
        return "âš ï¸ primaryValue ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    df2 = df.copy()
    if "countryName" not in df2.columns:
        if "partnerCode" in df2.columns:
            df2["countryName"] = df2["partnerCode"].apply(get_country_name_comtrade)
        else:
            df2["countryName"] = "ì•Œ ìˆ˜ ì—†ìŒ"
    
    top_3 = df2.sort_values(by="primaryValue", ascending=False).head(3)
    if len(top_3) == 0:
        return "âš ï¸ ìƒìœ„ êµ­ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    top_country = top_3.iloc[0]["countryName"]
    top_value = float(top_3.iloc[0]["primaryValue"])
    total_value = float(df2["primaryValue"].sum())
    market_share = (top_value / total_value * 100) if total_value > 0 else 0
    
    insight = f"""
ğŸ’¡ **AI ì¸ì‚¬ì´íŠ¸**:
- **{country_name}** ì‹œì¥ì—ì„œ HS Code **{hs_code}** í’ˆëª©ì€ **{top_country}**ì‚° ì œí’ˆ ë¹„ì¤‘ì´ ê°€ì¥ í½ë‹ˆë‹¤ (ì ìœ ìœ¨: **{market_share:.1f}%**)
- ì´ ê±°ë˜ì•¡: **${total_value:,.0f}**
- Top 3 íŒŒíŠ¸ë„ˆ: **{", ".join(top_3["countryName"].tolist())}**
"""
    return insight.strip()


# ==================== ì•„ë§ˆì¡´ ê²½ìŸì‚¬ ë¶„ì„ ì„¹ì…˜ ====================

def render_comtrade_analysis(key_prefix: str = "comtrade") -> None:
    def k(name: str) -> str:
        return f"{key_prefix}_{name}"
    
    settings = get_settings()
    cache_dir = settings["CACHE_DIR"]
    
    st.markdown(
        """
        <style>
          .small-muted{ color:#64748b; font-size:0.92rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    
    # ì„¸ì…˜ ì´ˆê¸°í™”
    if k("selected_hs_code") not in st.session_state:
        st.session_state[k("selected_hs_code")] = "382499"
    if k("use_cache") not in st.session_state:
        st.session_state[k("use_cache")] = True
    if k("target_year") not in st.session_state:
        st.session_state[k("target_year")] = "2022"
    
    try:
        default_end = int(st.session_state[k("target_year")])
    except Exception:
        default_end = 2022
    default_start = default_end - 2
    
    if k("start_year") not in st.session_state:
        st.session_state[k("start_year")] = default_start
    if k("end_year") not in st.session_state:
        st.session_state[k("end_year")] = default_end
    
    st.markdown("## ê¸€ë¡œë²Œ ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤")
    st.markdown('<p class="small-muted">UN Comtrade ê¸°ë°˜ ê¸€ë¡œë²Œ ë¬´ì—­ ë°ì´í„°</p>', unsafe_allow_html=True)
    
    # ìºì‹œ ì„¤ì •
    with st.expander("ìºì‹œ ì„¤ì •", expanded=False):
        c1, c2, c3 = st.columns([2, 1, 1])
        with c1:
            st.checkbox("ìºì‹œ ì‚¬ìš©", key=k("use_cache"))
            st.caption(f"í´ë”: `{cache_dir}` | ìœ íš¨: {CACHE_EXPIRY_DAYS}ì¼")
        with c2:
            info = get_cache_info(cache_dir)
            st.metric("ìºì‹œ íŒŒì¼", f"{info['count']}ê°œ")
        with c3:
            st.metric("ìš©ëŸ‰", f"{info['size_mb']} MB")
        
        if st.button("ğŸ—‘ï¸ ìºì‹œ ì‚­ì œ", key=k("clear_cache")):
            if clear_cache(cache_dir):
                st.success("ìºì‹œ ì‚­ì œ ì™„ë£Œ")
                st.rerun()
    
    use_cache: bool = bool(st.session_state.get(k("use_cache"), True))
    
    st.markdown("---")
    
    # HS Code ê²€ìƒ‰
    def _set_selected_hs(code: str) -> None:
        st.session_state[k("selected_hs_code")] = str(code)
    
    with st.expander("í’ˆëª©ëª…ìœ¼ë¡œ HS Code ì°¾ê¸°", expanded=True):
        search_col1, search_col2 = st.columns([3, 1])
        with search_col1:
            product_search = st.text_input("í’ˆëª©ëª… ì…ë ¥", placeholder="ì˜ˆ: í™”ì¥í’ˆ, ìƒ´í‘¸ ë“±", key=k("product_search_input"))
        with search_col2:
            st.markdown("<br>", unsafe_allow_html=True)
            search_btn = st.button("ê²€ìƒ‰", use_container_width=True, key=k("hs_search_btn"))
        
        if search_btn and product_search:
            results = search_hs_code_by_product(product_search)
            if results:
                st.success(f"âœ… '{product_search}' ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´")
                for idx, item in enumerate(results):
                    colA, colB, colC = st.columns([1, 5, 1])
                    with colA:
                        st.markdown(f"<span style='color:#16a34a;font-weight:800;font-size:1.1rem;'>{item['hs_code_6digit']}</span>", unsafe_allow_html=True)
                        if item.get("source"): st.caption(item["source"])
                    with colB:
                        st.markdown(f"{item.get('korean_name', '')}")
                        if item.get("english_name"): st.caption(item["english_name"][:120])
                    with colC:
                        st.button("ì„ íƒ", key=k(f"sel_{item['hs_code_6digit']}_{idx}"), use_container_width=True, on_click=_set_selected_hs, args=(item["hs_code_6digit"],))
                    if idx < len(results)-1: st.markdown("---")
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ë¶„ì„ ì„¤ì •
    col1, col2, col3, col4, col5 = st.columns([2, 1, 1, 1, 1])
    
    with col1:
        st.text_input("HS Code (6ìë¦¬)", key=k("selected_hs_code"), placeholder="ì˜ˆ: 382499")
    
    with col2:
        target_year = st.selectbox("ê¸°ì¤€ ì—°ë„", ["2022", "2021", "2020"], key=k("target_year"))
    
    with col3:
        reporter_options = {
            "ë¯¸êµ­": "842", "ì¤‘êµ­": "156", "í•œêµ­": "410", "ë…ì¼": "276", "ì¼ë³¸": "392",
            "ì˜êµ­": "826", "í”„ë‘ìŠ¤": "250", "ìºë‚˜ë‹¤": "124",
        }
        rep_name = st.selectbox("ë¶„ì„ ëŒ€ìƒêµ­", list(reporter_options.keys()), key=k("reporter_name"))
        rep_code = reporter_options[rep_name]
    
    year_options = [2020, 2021, 2022, 2023]
    try:
        default_end = int(target_year)
    except Exception:
        default_end = 2022
    
    with col4:
        start_year = st.selectbox("ì›”ë³„ ì‹œì‘", year_options, index=year_options.index(default_end-2) if (default_end-2) in year_options else 0, key=k("start_year"))
    with col5:
        end_year = st.selectbox("ì›”ë³„ ì¢…ë£Œ", year_options, key=k("end_year"))
    
    run_btn = st.button("ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True, key=k("run_btn"))
    
    if not run_btn:
        st.info("ğŸ’¡ HS Codeì™€ ì„¤ì •ì„ ì…ë ¥í•œ ë’¤ 'ë¶„ì„ ì‹¤í–‰'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        return
    
    current_hs = str(st.session_state.get(k("selected_hs_code"), "")).strip()
    if not current_hs:
        st.error("HS Codeë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    if start_year > end_year:
        end_year = start_year
    
    # ë°ì´í„° ìˆ˜ì§‘
    with st.spinner("ğŸ”„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("ìˆ˜ì… ì›”ë³„... (1/4)")
        monthly_import = fetch_monthly_data_optimized(current_hs, rep_code, "M", start_year, end_year, use_cache=use_cache, cache_dir=cache_dir)
        progress_bar.progress(25)
        
        status_text.text("ìˆ˜ì¶œ ì›”ë³„... (2/4)")
        monthly_export = fetch_monthly_data_optimized(current_hs, rep_code, "X", start_year, end_year, use_cache=use_cache, cache_dir=cache_dir)
        progress_bar.progress(50)
        
        status_text.text("ìˆ˜ì… ì—°ê°„... (3/4)")
        df_import = fetch_comtrade_data_module(current_hs, target_year, rep_code, flow_code="M", use_cache=use_cache, cache_dir=cache_dir)
        progress_bar.progress(75)
        
        status_text.text("ìˆ˜ì¶œ ì—°ê°„... (4/4)")
        df_export = fetch_comtrade_data_module(current_hs, target_year, rep_code, flow_code="X", use_cache=use_cache, cache_dir=cache_dir)
        progress_bar.progress(100)
        
        status_text.empty()
        progress_bar.empty()
    
    if all(x is None or len(x) == 0 for x in [monthly_import, monthly_export, df_import, df_export]):
        st.error("âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ê°€ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    st.markdown("---")
    
    # íƒ­ ë¶„ë¦¬
    tab_import, tab_export = st.tabs(["ìˆ˜ì… ë¶„ì„ (Buying)", "ìˆ˜ì¶œ ë¶„ì„ (Selling)"])
    
    # ===== ìˆ˜ì… íƒ­ =====
    with tab_import:
        st.markdown("### SY AI ë§ˆì¼“ ë¸Œë¦¬í•‘")
        if df_import is not None and len(df_import) > 0:
            df_import_filtered = df_import[df_import.get("countryName", "") != "ì „ì„¸ê³„"].copy()
            st.success(generate_market_insight(df_import_filtered, current_hs, rep_name))
        else:
            st.info("ë°ì´í„° ì—†ìŒ")
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ìµœê·¼ ì„±ì¥ ì¶”ì´ (ì›”ë³„)")
        if monthly_import is not None and len(monthly_import) > 0:
            fig = create_volume_trend_chart(monthly_import, current_hs, "ìˆ˜ì…")
            if fig: st.plotly_chart(fig, use_container_width=True)
            
            total_val = float(monthly_import["value"].sum())
            total_wgt = float(monthly_import["weight"].sum())
            c1, c2, c3 = st.columns(3)
            c1.metric("ì´ ìˆ˜ì…ì•¡", f"${total_val:,.0f}")
            c2.metric("ì´ ìˆ˜ì…ëŸ‰", f"{total_wgt:,.2f} kg")
            c3.metric("í‰ê·  ë‹¨ê°€", f"${(total_val/total_wgt) if total_wgt>0 else 0:,.2f}/kg")
        
        st.markdown("---")
        st.markdown("### ğŸ—ºï¸ ê¸€ë¡œë²Œ íŒŒíŠ¸ë„ˆ ë¶„í¬")
        if df_import is not None and len(df_import) > 0:
            fig_map, _ = create_partner_value_map(df_import_filtered, title=f"{target_year}ë…„ {rep_name} ìˆ˜ì… íŒŒíŠ¸ë„ˆ ë¶„í¬")
            if fig_map: st.plotly_chart(fig_map, use_container_width=True)
            
            st.markdown("#### Top 15 êµ­ê°€")
            market_table = create_market_share_table(df_import_filtered, "ìˆ˜ì…")
            if market_table is not None:
                st.dataframe(market_table, use_container_width=True, hide_index=True)

    # ===== ìˆ˜ì¶œ íƒ­ =====
    with tab_export:
        st.markdown("### ğŸ¤– AI ê¸€ë¡œë²Œ ì‹œì¥ ë¶„ì„ ìš”ì•½")
        if df_export is not None and len(df_export) > 0:
            df_export_filtered = df_export[df_export.get("countryName", "") != "ì „ì„¸ê³„"].copy()
            st.success(generate_market_insight(df_export_filtered, current_hs, rep_name))
        else:
            st.info("ë°ì´í„° ì—†ìŒ")
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ìµœê·¼ ì„±ì¥ ì¶”ì´ (ì›”ë³„)")
        if monthly_export is not None and len(monthly_export) > 0:
            fig = create_volume_trend_chart(monthly_export, current_hs, "ìˆ˜ì¶œ")
            if fig: st.plotly_chart(fig, use_container_width=True)
            
            total_val = float(monthly_export["value"].sum())
            total_wgt = float(monthly_export["weight"].sum())
            c1, c2, c3 = st.columns(3)
            c1.metric("ì´ ìˆ˜ì¶œì•¡", f"${total_val:,.0f}")
            c2.metric("ì´ ìˆ˜ì¶œëŸ‰", f"{total_wgt:,.2f} kg")
            c3.metric("í‰ê·  ë‹¨ê°€", f"${(total_val/total_wgt) if total_wgt>0 else 0:,.2f}/kg")
        
        st.markdown("---")
        st.markdown("### ğŸ—ºï¸ ê¸€ë¡œë²Œ íŒŒíŠ¸ë„ˆ ë¶„í¬")
        if df_export is not None and len(df_export) > 0:
            fig_map, _ = create_partner_value_map(df_export_filtered, title=f"{target_year}ë…„ {rep_name} ìˆ˜ì¶œ íŒŒíŠ¸ë„ˆ ë¶„í¬")
            if fig_map: st.plotly_chart(fig_map, use_container_width=True)
            
            st.markdown("#### Top 15 êµ­ê°€")
            market_table = create_market_share_table(df_export_filtered, "ìˆ˜ì¶œ")
            if market_table is not None:
                st.dataframe(market_table, use_container_width=True, hide_index=True)
    


# ==================== ë©”ì¸ ì‹¤í–‰ ====================

def main():
    st.set_page_config(
        page_title="í•´ì™¸ì§„ì¶œ ì „ëµ ëŒ€ì‹œë³´ë“œ",
        page_icon="ğŸš¢",
        layout="wide",
    )

        # ==================== ğŸ”½ ì—¬ê¸°ì— ì‚¬ì´ë“œë°” ì½”ë“œ ì‚½ì…! ====================
    import base64
    
    # ì‚¬ì´ë“œë°” CSS
    st.markdown("""
        <style>
        [data-testid="stSidebarNav"] { display: none; }
        section[data-testid="stSidebar"] { 
            background: #ffffff !important;
            border-right: 1px solid #e5e7eb;
        }
        .stButton>button {
            background: #051161 !important;
            color: #ffffff !important;
            border: none !important;
            border-radius: 8px;
            padding: 10px 14px;
            font-weight: 700;
            transition: 0.3s;
        }
        .stButton>button:hover {
            background: rgba(5,17,97,0.85) !important;
            box-shadow: 0 4px 12px rgba(5,17,97,0.3) !important;
        }
        .logo-box{
            background: rgba(255,255,255,0.6);
            border: 1px solid #e5e7eb;
            border-radius: 14px;
            padding: 14px 12px;
            margin-bottom: 10px;
            text-align:center;
        }
        .logo-img{
            max-width: 150px;
            width: 100%;
            height: auto;
            display:block;
            margin: 0 auto;
        }
        .small-muted{
            color:#64748b;
            font-size: 0.85rem;
            font-weight: 600;
            letter-spacing: 0.2px;
        }
        </style>
    """, unsafe_allow_html=True)
    
    with st.sidebar:
        # 1) êµ­ê°€ë³„ ìˆ˜ì¶œì… ë°ì´í„°
        with st.expander("1) í•´ì™¸ì§„ì¶œ ì „ëµ í—ˆë¸Œ", expanded=False):
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("ì‹œì¥ë™í–¥", use_container_width=True, key="nav_cn_1"):
                    st.switch_page("pages/macro_1.py")
            with col2:
                if st.button("ì „ëµë¶„ì„", use_container_width=True, key="nav_cn_2"):
                    st.switch_page("pages/micro_1.py")
            with col3:
                if st.button("ê·œì œì§„ë‹¨", use_container_width=True, key="nav_cn_3"):
                    st.switch_page("pages/mac_mic_1.py")

        # 2) SEO ì„œë¹„ìŠ¤
        with st.expander("2) SEO ì„œë¹„ìŠ¤", expanded=False):
            if st.button("ë°”ë¡œê°€ê¸°", use_container_width=True, key="nav_news"):
                st.switch_page("pages/junghyun.py")

        # 3) AI ë°”ì´ì–´ ë§¤ì¹­ ì„œë¹„ìŠ¤
        with st.expander("3) AI ë°”ì´ì–´ ë§¤ì¹­ ì„œë¹„ìŠ¤", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ë°”ì´ì–´ ì°¾ê¸°", use_container_width=True, key="nav_ai_1"):
                    st.switch_page("pages/03_ai_chatbot.py")
            with col2:
                if st.button("ì „ì‹œíšŒ ì¼ì •", use_container_width=True, key="nav_ai_2"):
                    st.switch_page("pages/buyer_maps.py")        

        # 4) í™˜ìœ¨ ì •ë³´ í™•ì¸
        with st.expander("4) í™˜ìœ¨ ì •ë³´ í™•ì¸", expanded=False):
            if st.button("ë°”ë¡œê°€ê¸°", use_container_width=True, key="nav_ex"):
                st.switch_page("pages/exchange_rate.py")

         # 5) ë¬´ì—­ ì„œë¥˜ ìë™ ì™„ì„±
        with st.expander("5) ë¬´ì—­ ì„œë¥˜ ìë™ ì™„ì„±", expanded=False):
            if st.button("ë°”ë¡œê°€ê¸°", use_container_width=True, key="nav_fx"):
                st.switch_page("pages/auto_docs.py")

        # ë¡œê³  ì˜ì—­
        logo_path = "assets/logo.png"
        if os.path.exists(logo_path):
            logo_b64 = base64.b64encode(open(logo_path, "rb").read()).decode()
            st.markdown(
                f"""
                <div class="logo-box">
                  <img class="logo-img" src="data:image/png;base64,{logo_b64}" alt="logo"/>
                  <div class="small-muted" style="margin-top:8px; text-align:center;">
                    KITA AX MASTER TEAM4
                  </div>
                </div>
                """,
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                """
                <div class="logo-box">
                  <div style="font-size:1.15rem; font-weight:900; color:#0f172a;">ğŸš€ SEO Suite</div>
                  <div class="small-muted" style="margin-top:6px;">KITA AX MASTER TEAM4</div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("---")

        # í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°
        if st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True, key="go_home_sidebar"):
            st.switch_page("dashboard.py")
    
    
    # CSS
    st.markdown("""
    <style>
    .block-container{ padding-top: 2rem; }
    </style>
    """, unsafe_allow_html=True)
    
    
    st.markdown("# ğŸš¢ í•´ì™¸ì§„ì¶œ ì „ëµ í—ˆë¸Œ")
    
    st.markdown("---")
    
    # ê±°ì‹œì  ë¶„ì„ ì‹¤í–‰
    render_comtrade_analysis(key_prefix="macro")

if __name__ == "__main__":
    main()



# --- Footer ---
st.divider()
st.markdown("""
<div style='text-align: center; color: #718096; font-size: 0.9em;'>
    <p>Global E-commerce All In One Solution</p>
    <p>Developed by Seyeon Global Connect</p>
</div>
""", unsafe_allow_html=True)