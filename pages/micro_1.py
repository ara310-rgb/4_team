"""
UN Comtrade + Amazon SerpApi í†µí•© ë¶„ì„ ëª¨ë“ˆ
ì•„ë§ˆì¡´ ì§„ì¶œ ì „ëµ ì†”ë£¨ì…˜ ëŒ€ì‹œë³´ë“œ + ê²½ìŸì‚¬ ë¶„ì„

êµ¬ì„±:
1. [ê¸°ë°˜] í’ˆëª©ëª…ìœ¼ë¡œ HS Code ì°¾ê¸°
2. [STEP 1] ê±°ì‹œì  ì‹œì¥ ë¶„ì„ (UN Comtrade ìˆ˜ì¶œì… í†µê³„)
3. [STEP 2] ë¯¸ì‹œì  í˜„ì§€ ë¶„ì„ (Amazon ì‹¤ì‹œê°„ ê°€ê²© ì¡°ì‚¬)
4. [STEP 3] ê²½ìŸì‚¬ Top 15 ìƒì„¸ ë¶„ì„ (ì‹ ê·œ ì¶”ê°€)
"""

from __future__ import annotations

import json
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import streamlit as st
from dotenv import load_dotenv
from plotly.subplots import make_subplots
from urllib.parse import quote
import re
import openai
from openai import OpenAI

# ==================== ì„¤ì • ë° ìƒìˆ˜ ====================

CACHE_EXPIRY_DAYS = 7
AMAZON_CACHE_FILE = "amazon_cache.json"

MODULE_DIR = os.path.dirname(os.path.abspath(__file__))
HS_CODE_CSV_PATH = os.path.join(MODULE_DIR, "HScode_customs.csv")


CATEGORY_HINTS = {
    "í™”ì¥í’ˆ": ["3303", "3304", "3305", "3306", "3307"],
    "ì½”ìŠ¤ë©”í‹±": ["3303", "3304", "3305", "3306", "3307"],
    "í–¥ìˆ˜": ["3303"],
    "ë©”ì´í¬ì—…": ["3304"],
    "ìŠ¤í‚¨ì¼€ì–´": ["3304"],
    "ìƒ´í‘¸": ["3305"],
    "ì¹˜ì•½": ["3306"],
    "ë¹„ëˆ„": ["3401"],
    "ì„¸ì œ": ["3402"],
}

PACKAGING_NEGATIVE_KEYWORDS = [
    "í¬ì¥", "í¬ì¥ìš©", "ì›ì§€", "ì¹´í†¤", "ìƒì", "í•„ë¦„", "ë¼ë²¨", "ìš©ê¸°", "ë³‘", "ìº¡", "ëšœê»‘",
    "ì¼€ì´ìŠ¤", "ìŠ¤í‹°ì»¤", "ë°•ìŠ¤", "í¬ì¥ì¬", "ë´‰íˆ¬"
]

# ==================== í™˜ê²½ ì„¤ì • ====================

def _get_env_or_session(key: str) -> Optional[str]:
    if key in st.session_state and st.session_state.get(key):
        return str(st.session_state.get(key)).strip()
    env_val = os.getenv(key)
    if env_val:
        return str(env_val).strip()
    return None


def get_settings() -> Dict[str, Optional[str]]:
    load_dotenv()
    
    primary = _get_env_or_session("UN_COMTRADE_KEY")
    if not primary:
        primary = _get_env_or_session("UN_API_KEY")
        
    secondary = _get_env_or_session("UN_SECOND_API_KEY")
    openai_key = _get_env_or_session("OPENAI_API_KEY")
    serpapi = _get_env_or_session("SERPAPI_KEY")  # âœ… ìˆ˜ì •: RAINFOREST_API â†’ SERPAPI_KEY
    
    cache_dir = _get_env_or_session("CACHE_DIR") or "./comtrade_cache"
    cache_dir = str(cache_dir)
    
    if not os.path.exists(cache_dir):
        try:
            os.makedirs(cache_dir, exist_ok=True)
        except Exception:
            cache_dir = "./comtrade_cache_temp"
            os.makedirs(cache_dir, exist_ok=True)
    
    return {
        "PRIMARY_KEY": primary,
        "SECONDARY_KEY": secondary,
        "OPENAI_KEY": openai_key,
        "SERPAPI": serpapi,  # âœ… ìˆ˜ì •
        "CACHE_DIR": cache_dir,
    }

# ==================== OpenAI í˜¸ì¶œ í•¨ìˆ˜ ====================

def generate_openai_response(prompt: str) -> str:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    settings = get_settings()
    api_key = settings.get("OPENAI_KEY")
    
    if not api_key:
        return "âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    try:
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ì´ì»¤ë¨¸ìŠ¤ ë° ë¬´ì—­ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ==================== ìˆ˜ëŸ‰ ì¶”ì¶œ ë° ê°€ì„±ë¹„ ë¶„ì„ ====================

def extract_quantity_val(title: str) -> int:
    """ì œí’ˆëª…ì—ì„œ ìˆ˜ëŸ‰ ì •ë³´ë¥¼ 'ìˆ«ì'ë¡œë§Œ ì¶”ì¶œí•˜ì—¬ ê°€ì„±ë¹„ ê³„ì‚°ì— í™œìš©í•©ë‹ˆë‹¤."""
    match = re.search(r'(\d+)\s?(?:Pack|Count|Pairs|Items|Pcs|Units)', title, re.IGNORECASE)
    
    if match:
        return int(match.group(1))
    
    nums = re.findall(r'\d+', title)
    if nums:
        val = int(nums[-1])
        return val if val > 0 else 1
        
    return 1

def summarize_description_backup(asin: str, product_title: str, price: float) -> dict:
    """ì œí’ˆ ìƒì„¸ ì •ë³´ë¡œ ê°€ì„±ë¹„ ë° í•œêµ­ ì§„ì¶œ ì „ëµ ë¶„ì„ (ë”ë¯¸ ë°ì´í„° ëª¨ë“œ)"""
    
    domain = st.session_state.get("amazon_amazon_domain", "amazon.com")
    
    # ë”ë¯¸ ì œí’ˆ íŠ¹ì§• ë°ì´í„°
    dummy_features = [
        "Premium quality ingredients for best results",
        "Long-lasting formula that stays fresh all day",
        "Dermatologist tested and approved",
        "Suitable for all skin types",
        "Easy to apply with smooth texture",
        "Paraben-free and cruelty-free formula",
        "Travel-friendly packaging included"
    ]
    
    bullets = "\n".join(dummy_features)
    
    qty = extract_quantity_val(product_title)
    safe_price = price if price and price > 0 else 0
    unit_price = safe_price / qty if qty > 0 else 0
    
    country_info = {
        "amazon.com": {"name": "ë¯¸êµ­", "focus": "ì„±ë¶„ íˆ¬ëª…ì„±, FDA ê·œì •, ëŒ€ìš©ëŸ‰ ê°€ì„±ë¹„, ë‹¤ì–‘í•œ ì¸ì¢…ë³„ í”¼ë¶€í†¤ ëŒ€ì‘"},
        "amazon.co.jp": {"name": "ì¼ë³¸", "focus": "íŒ¨í‚¤ì§• ë””ìì¸ì˜ ì •êµí•¨, í›„ìƒë…¸ë™ì„±(MHLW) ê·œì •, ë¯¸ë°±/ë³´ìŠµ ì„¸ë¶„í™”, ì†ŒëŸ‰ íŒ¨í‚¤ì§€ ì„ í˜¸"},
        "amazon.co.uk": {"name": "ì˜êµ­", "focus": "ì¹œí™˜ê²½/ë¹„ê±´ ì¸ì¦, ìœ ëŸ½ í™”ì¥í’ˆ ê·œì •(CPNP), ì „í†µì  ë¸Œëœë“œ ì‹ ë¢°ë„, ì§€ì† ê°€ëŠ¥í•œ í¬ì¥"},
        "amazon.de": {"name": "ë…ì¼", "focus": "ë”ë§ˆí…ŒìŠ¤íŠ¸(Dermatest) ì¸ì¦ ì¤‘ìš”ë„, ìœ ê¸°ë† ì„±ë¶„, ì‹¤ìš©ì  íŒ¨í‚¤ì§•, ì„±ë¶„ ë¶„ì„ ê²°ê³¼ ì¤‘ì‹œ"}
    }
    
    selected_country = country_info.get(domain, {"name": "í•´ì™¸", "focus": "í˜„ì§€ ê·œì • ë° ì†Œë¹„ì ì„ í˜¸ë„"})

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ ê¸°ì—…ì˜ {selected_country['name']} ì•„ë§ˆì¡´ ì§„ì¶œì„ ë•ëŠ” ìˆ˜ì¶œ ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
    í˜„ì§€ 1ìœ„ ì œí’ˆì„ 'ì •ë³µí•´ì•¼ í•  íƒ€ê²Ÿ'ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì•„ë˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

    [ë¶„ì„ ë°ì´í„°]
    - ì§„ì¶œ ëŒ€ìƒêµ­: {selected_country['name']} (í”Œë«í¼: {domain})
    - í˜„ì§€ ì‹œì¥ íŠ¹ì„± ë° ê·œì œ: {selected_country['focus']}
    - ê²½ìŸì‚¬ ì œí’ˆëª…: {product_title}
    - í˜„ì§€ íŒë§¤ê°€: ${safe_price} ({qty}ê°œì…, ê°œë‹¹ ${unit_price:.2f})
    - ê²½ìŸì‚¬ ì œí’ˆ íŠ¹ì§•: {bullets[:500]}

    [ìˆ˜ì¶œ ì „ëµ ë¦¬í¬íŠ¸ êµ¬ì„± ê°€ì´ë“œë¼ì¸]
    1. {selected_country['name']} ì‹œì¥ 1ìœ„ ë¹„ê²°: ì´ ì œí’ˆì˜ í˜„ì§€ ì„±ê³µ ê³µì‹ ë¶„ì„
    2. í•œêµ­ ê¸°ì—…ì˜ ê¸°íšŒ: ê²½ìŸì‚¬ ì œí’ˆ ëŒ€ë¹„ í•œêµ­ ì œí’ˆì´ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìš°ìœ„(ì„±ë¶„, ë””ìì¸, ë¦¬ë·° ì•½ì  ê³µëµ)
    3. ìˆ˜ì¶œ ê°€ê²© í¬ì§€ì…”ë‹: ê²½ìŸì‚¬ ë‹¨ê°€(${unit_price:.2f}) ê¸°ì¤€, í•œêµ­ ê¸°ì—…ì˜ ì ì • ìˆ˜ì¶œê°€ ì œì•ˆ
    4. í˜„ì§€í™” ë° ê·œì œ ëŒ€ì‘: {selected_country['name']} ìˆ˜ì¶œ ì‹œ í•„ìˆ˜ ì¸ì¦(FDA, MHLW, CPNP ë“±) ë° íŒ¨í‚¤ì§• ì¡°ì–¸
    """
        
    analysis_report = generate_openai_response(prompt)
    
    return {
        "analysis": analysis_report,
        "unit_price": unit_price,
        "qty": qty
    }
    
# ==================== í…ìŠ¤íŠ¸ ìœ í‹¸ ====================

def normalize_text(s: str) -> str:
    if s is None:
        return ""
    s = str(s).lower()
    s = re.sub(r"[\(\)\[\]\{\}]", " ", s)
    s = re.sub(r"[^0-9a-zA-Zê°€-í£\sÂ·ã†\-_]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s


def has_any(text: str, keywords: List[str]) -> bool:
    return any(k in text for k in keywords)


# ==================== í—¬í¼ í•¨ìˆ˜ (Comtrade) ====================

# def get_country_name_comtrade(code) -> str:
    if pd.isna(code):
        return "ì•Œ ìˆ˜ ì—†ìŒ"
    try:
        code = int(code)
        return COUNTRY_CODE_MAP.get(code, f"êµ­ê°€ì½”ë“œ {code}")
    except Exception:
        return "ì•Œ ìˆ˜ ì—†ìŒ"


# ==================== ìºì‹± (Comtrade) ====================

def get_cache_filename(cache_dir: str, hs_code: str, reporter_code: str, flow_code: str, data_type: str) -> str:
    return os.path.join(cache_dir, f"{hs_code}_{reporter_code}_{flow_code}_{data_type}.json")


def is_cache_valid(cache_file: str) -> bool:
    if not os.path.exists(cache_file):
        return False
    file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
    return datetime.now() - file_time < timedelta(days=CACHE_EXPIRY_DAYS)


def load_from_cache(cache_file: str) -> Optional[pd.DataFrame]:
    try:
        with open(cache_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            if data:
                return pd.DataFrame(data)
    except Exception:
        return None
    return None


def save_to_cache(cache_file: str, df: pd.DataFrame) -> bool:
    try:
        if df is not None and len(df) > 0:
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(df.to_dict("records"), f, ensure_ascii=False)
            return True
    except Exception:
        return False
    return False


def get_cache_info(cache_dir: str) -> Dict[str, float]:
    if not os.path.exists(cache_dir):
        return {"count": 0, "size_mb": 0.0}
    files = [f for f in os.listdir(cache_dir) if f.endswith(".json")]
    total_size = sum(os.path.getsize(os.path.join(cache_dir, f)) for f in files)
    return {"count": len(files), "size_mb": round(total_size / (1024 * 1024), 2)}


def clear_cache(cache_dir: str) -> bool:
    try:
        if os.path.exists(cache_dir):
            for file in os.listdir(cache_dir):
                if file.endswith(".json"):
                    os.remove(os.path.join(cache_dir, file))
        return True
    except Exception:
        return False


# ==================== Amazon SerpApi ====================

def get_dummy_amazon_data(query: str, amazon_domain: str = "amazon.com") -> List[dict]:
    """ê²€ìƒ‰ì–´ì™€ ë„ë©”ì¸ì— ë”°ë¥¸ ë”ë¯¸ ë°ì´í„° ìƒì„±"""
    
    # ë„ë©”ì¸ë³„ í†µí™” ë° ê°€ê²© ë°°ìœ¨
    domain_config = {
        "amazon.com": {"currency": "$", "multiplier": 1.0, "lang": "en"},
        "amazon.co.jp": {"currency": "Â¥", "multiplier": 150.0, "lang": "jp"},
        "amazon.co.uk": {"currency": "Â£", "multiplier": 0.8, "lang": "en"},
        "amazon.de": {"currency": "â‚¬", "multiplier": 0.9, "lang": "de"},
    }
    
    config = domain_config.get(amazon_domain, domain_config["amazon.com"])
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë”ë¯¸ ì œí’ˆ ë°ì´í„°
    dummy_products = {
        "cosmetic": [
            {"name": "SHEGLAM Color Bloom Liquid Blush Makeup Set", "brand": "SHEGLAM", "base_price": 15.99, "rating": 4.5, "reviews": 12847, "asin": "B0BXYZ1234"},
            {"name": "Maybelline New York Instant Age Rewind Set", "brand": "Maybelline", "base_price": 24.99, "rating": 4.4, "reviews": 89234, "asin": "B0BXYZ1235"},
            {"name": "e.l.f. Cosmetics Flawless Finish Foundation Kit", "brand": "e.l.f.", "base_price": 18.00, "rating": 4.3, "reviews": 45621, "asin": "B0BXYZ1236"},
            {"name": "NYX Professional Makeup Ultimate Set 16 Colors", "brand": "NYX", "base_price": 22.00, "rating": 4.6, "reviews": 34521, "asin": "B0BXYZ1237"},
            {"name": "COVERGIRL Clean Fresh Skincare Set", "brand": "COVERGIRL", "base_price": 29.99, "rating": 4.2, "reviews": 23456, "asin": "B0BXYZ1238"},
            {"name": "L'Oreal Paris True Match Foundation Set", "brand": "L'Oreal", "base_price": 32.99, "rating": 4.4, "reviews": 67890, "asin": "B0BXYZ1239"},
            {"name": "Revlon ColorStay Makeup Collection", "brand": "Revlon", "base_price": 27.50, "rating": 4.1, "reviews": 54321, "asin": "B0BXYZ1240"},
            {"name": "Neutrogena Hydro Boost Skincare Set", "brand": "Neutrogena", "base_price": 35.99, "rating": 4.5, "reviews": 78901, "asin": "B0BXYZ1241"},
            {"name": "CeraVe Daily Skincare Routine Bundle", "brand": "CeraVe", "base_price": 42.00, "rating": 4.7, "reviews": 123456, "asin": "B0BXYZ1242"},
            {"name": "The Ordinary Skincare Starter Set", "brand": "The Ordinary", "base_price": 38.00, "rating": 4.6, "reviews": 98765, "asin": "B0BXYZ1243"},
            {"name": "Clinique 3-Step Skincare System", "brand": "Clinique", "base_price": 45.00, "rating": 4.3, "reviews": 34567, "asin": "B0BXYZ1244"},
            {"name": "Olay Regenerist Micro-Sculpting Set", "brand": "Olay", "base_price": 48.99, "rating": 4.4, "reviews": 56789, "asin": "B0BXYZ1245"},
            {"name": "Korean Beauty 10-Step Skincare Kit", "brand": "K-Beauty", "base_price": 55.00, "rating": 4.5, "reviews": 23456, "asin": "B0BXYZ1246"},
            {"name": "Fenty Beauty Soft Matte Foundation Set", "brand": "Fenty Beauty", "base_price": 52.00, "rating": 4.6, "reviews": 87654, "asin": "B0BXYZ1247"},
            {"name": "Charlotte Tilbury Magic Set", "brand": "Charlotte Tilbury", "base_price": 65.00, "rating": 4.7, "reviews": 45678, "asin": "B0BXYZ1248"},
        ],
        "shampoo": [
            {"name": "Pantene Pro-V Daily Moisture Renewal Shampoo", "brand": "Pantene", "base_price": 12.99, "rating": 4.5, "reviews": 45678, "asin": "B0CSHP1234"},
            {"name": "Head & Shoulders Clinical Strength Shampoo", "brand": "Head & Shoulders", "base_price": 15.99, "rating": 4.4, "reviews": 67890, "asin": "B0CSHP1235"},
            {"name": "OGX Biotin & Collagen Shampoo Set", "brand": "OGX", "base_price": 18.99, "rating": 4.3, "reviews": 34521, "asin": "B0CSHP1236"},
            {"name": "Dove Nutritive Solutions Shampoo Bundle", "brand": "Dove", "base_price": 14.50, "rating": 4.2, "reviews": 89012, "asin": "B0CSHP1237"},
            {"name": "TRESemmÃ© Keratin Smooth Shampoo Pack", "brand": "TRESemmÃ©", "base_price": 16.99, "rating": 4.1, "reviews": 23456, "asin": "B0CSHP1238"},
            {"name": "Moroccanoil Hydrating Shampoo", "brand": "Moroccanoil", "base_price": 28.00, "rating": 4.6, "reviews": 56789, "asin": "B0CSHP1239"},
            {"name": "Olaplex No.4 Bond Maintenance Shampoo", "brand": "Olaplex", "base_price": 30.00, "rating": 4.7, "reviews": 78901, "asin": "B0CSHP1240"},
            {"name": "Aussie Miracle Moist Shampoo 3-Pack", "brand": "Aussie", "base_price": 19.99, "rating": 4.3, "reviews": 34567, "asin": "B0CSHP1241"},
            {"name": "Herbal Essences Bio:Renew Shampoo Set", "brand": "Herbal Essences", "base_price": 17.50, "rating": 4.2, "reviews": 45678, "asin": "B0CSHP1242"},
            {"name": "Redken All Soft Shampoo for Dry Hair", "brand": "Redken", "base_price": 25.00, "rating": 4.5, "reviews": 23456, "asin": "B0CSHP1243"},
            {"name": "Briogeo Don't Despair Repair Shampoo", "brand": "Briogeo", "base_price": 36.00, "rating": 4.6, "reviews": 12345, "asin": "B0CSHP1244"},
            {"name": "Living Proof Full Shampoo", "brand": "Living Proof", "base_price": 32.00, "rating": 4.4, "reviews": 34567, "asin": "B0CSHP1245"},
            {"name": "Pureology Hydrate Shampoo", "brand": "Pureology", "base_price": 38.00, "rating": 4.5, "reviews": 45678, "asin": "B0CSHP1246"},
            {"name": "Function of Beauty Custom Shampoo", "brand": "Function of Beauty", "base_price": 29.99, "rating": 4.3, "reviews": 56789, "asin": "B0CSHP1247"},
            {"name": "KÃ©rastase Nutritive Shampoo", "brand": "KÃ©rastase", "base_price": 42.00, "rating": 4.7, "reviews": 23456, "asin": "B0CSHP1248"},
        ],
        "default": [
            {"name": f"Premium {query.title()} Product Set - Professional Grade", "brand": "TopBrand", "base_price": 29.99, "rating": 4.5, "reviews": 15678, "asin": "B0CDEF1234"},
            {"name": f"Essential {query.title()} Collection - Best Seller", "brand": "EssentialCo", "base_price": 24.99, "rating": 4.4, "reviews": 23456, "asin": "B0CDEF1235"},
            {"name": f"Deluxe {query.title()} Bundle - Value Pack", "brand": "DeluxeBrand", "base_price": 34.99, "rating": 4.3, "reviews": 12345, "asin": "B0CDEF1236"},
            {"name": f"Professional {query.title()} Kit - Complete Set", "brand": "ProLine", "base_price": 39.99, "rating": 4.6, "reviews": 34567, "asin": "B0CDEF1237"},
            {"name": f"Natural {query.title()} Organic Collection", "brand": "NaturalCo", "base_price": 27.50, "rating": 4.2, "reviews": 8901, "asin": "B0CDEF1238"},
            {"name": f"Budget {query.title()} Starter Pack", "brand": "ValueBrand", "base_price": 15.99, "rating": 4.1, "reviews": 45678, "asin": "B0CDEF1239"},
            {"name": f"Luxury {query.title()} Premium Edition", "brand": "LuxuryLine", "base_price": 55.00, "rating": 4.7, "reviews": 7890, "asin": "B0CDEF1240"},
            {"name": f"Everyday {query.title()} Daily Use Set", "brand": "DailyBrand", "base_price": 19.99, "rating": 4.3, "reviews": 56789, "asin": "B0CDEF1241"},
            {"name": f"Advanced {query.title()} Formula Plus", "brand": "AdvancedCo", "base_price": 32.00, "rating": 4.4, "reviews": 23456, "asin": "B0CDEF1242"},
            {"name": f"Classic {query.title()} Traditional Set", "brand": "ClassicBrand", "base_price": 22.50, "rating": 4.2, "reviews": 12345, "asin": "B0CDEF1243"},
            {"name": f"Modern {query.title()} Innovation Series", "brand": "ModernCo", "base_price": 42.00, "rating": 4.5, "reviews": 34567, "asin": "B0CDEF1244"},
            {"name": f"Eco-Friendly {query.title()} Green Edition", "brand": "EcoBrand", "base_price": 28.99, "rating": 4.4, "reviews": 8901, "asin": "B0CDEF1245"},
            {"name": f"Travel Size {query.title()} Mini Set", "brand": "TravelCo", "base_price": 14.99, "rating": 4.1, "reviews": 45678, "asin": "B0CDEF1246"},
            {"name": f"Family {query.title()} Mega Pack", "brand": "FamilyBrand", "base_price": 48.00, "rating": 4.3, "reviews": 23456, "asin": "B0CDEF1247"},
            {"name": f"Sensitive {query.title()} Gentle Care", "brand": "GentleCo", "base_price": 26.50, "rating": 4.5, "reviews": 12345, "asin": "B0CDEF1248"},
        ]
    }
    
    # ê²€ìƒ‰ì–´ì— ë”°ë¥¸ ì œí’ˆ ì„ íƒ
    query_lower = query.lower()
    if "cosmetic" in query_lower or "makeup" in query_lower or "beauty" in query_lower or "skin" in query_lower:
        products = dummy_products["cosmetic"]
    elif "shampoo" in query_lower or "hair" in query_lower or "conditioner" in query_lower:
        products = dummy_products["shampoo"]
    else:
        products = dummy_products["default"]
    
    # ê²°ê³¼ ìƒì„±
    results = []
    for p in products:
        adjusted_price = round(p["base_price"] * config["multiplier"], 2)
        results.append({
            "ì œí’ˆëª…": p["name"],
            "ë¸Œëœë“œ": p["brand"],
            "ê°€ê²©": adjusted_price,
            "ë³„ì ": p["rating"],
            "ë¦¬ë·°ìˆ˜": p["reviews"],
            "asin": p["asin"],
            "ë§í¬": f"https://{amazon_domain}/dp/{p['asin']}",
        })
    
    return results


def fetch_amazon_market_data(query: str, amazon_domain: str = "amazon.com") -> Optional[List[dict]]:
    """ì•„ë§ˆì¡´ ì œí’ˆ ê²€ìƒ‰ (ë”ë¯¸ ë°ì´í„° ëª¨ë“œ)"""
    
    cache_key = f"{amazon_domain}_{query}"
    
    # ìºì‹œ í™•ì¸
    if os.path.exists(AMAZON_CACHE_FILE):
        try:
            with open(AMAZON_CACHE_FILE, "r", encoding="utf-8") as f:
                cache = json.load(f)
        except Exception:
            cache = {}
    else:
        cache = {}
    
    if cache_key in cache:
        st.info("âœ… ì•„ë§ˆì¡´ ë°ì´í„° ìºì‹œì—ì„œ ë¡œë“œ!")
        return cache[cache_key]
    
    # ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
    st.info("ğŸ”„ ë”ë¯¸ ë°ì´í„° ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘... (SerpApi ë¹„í™œì„±í™”)")
    
    try:
        results = get_dummy_amazon_data(query, amazon_domain)
        
        # ìºì‹œ ì €ì¥
        cache[cache_key] = results
        with open(AMAZON_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
        
        st.success(f"âœ… {len(results)}ê°œ ì œí’ˆ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
        return results
    
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def get_dummy_reviews() -> List[dict]:
    """ë”ë¯¸ ë¦¬ë·° ë°ì´í„° ìƒì„±"""
    dummy_reviews = [
        {"rating": 5, "title": "Excellent product!", "body": "This is the best product I've ever used. Great quality and fast shipping. Love it! Works perfectly and lasts long.", "verified": True},
        {"rating": 5, "title": "Highly recommend", "body": "Amazing product! Exceeded my expectations. The quality is excellent and it arrived quickly.", "verified": True},
        {"rating": 4, "title": "Good value for money", "body": "Very good product overall. Works well and the price is reasonable. Would buy again.", "verified": True},
        {"rating": 5, "title": "Perfect!", "body": "Exactly what I was looking for. Great quality, perfect size, and amazing results.", "verified": True},
        {"rating": 4, "title": "Nice product", "body": "Good quality product. A bit expensive but worth it. Shipping was fast.", "verified": True},
        {"rating": 3, "title": "It's okay", "body": "Product is decent but not as good as I expected. Average quality.", "verified": True},
        {"rating": 5, "title": "Love this!", "body": "Best purchase I've made in a while. Works great and the quality is superb.", "verified": True},
        {"rating": 2, "title": "Disappointed", "body": "Not what I expected. Quality is poor and it doesn't work as advertised.", "verified": False},
        {"rating": 4, "title": "Good but could be better", "body": "Overall satisfied with the product. Works well but packaging could be improved.", "verified": True},
        {"rating": 5, "title": "5 stars!", "body": "Amazing! Perfect for my needs. Would definitely recommend to others.", "verified": True},
        {"rating": 1, "title": "Terrible", "body": "Worst product ever. Broke after one use. Waste of money. Don't buy this.", "verified": False},
        {"rating": 4, "title": "Pretty good", "body": "Good product for the price. Does what it's supposed to do. Happy with my purchase.", "verified": True},
        {"rating": 5, "title": "Outstanding quality", "body": "The quality is excellent. Best product in this category. Highly recommend!", "verified": True},
        {"rating": 3, "title": "Average", "body": "It's an average product. Nothing special but gets the job done.", "verified": True},
        {"rating": 4, "title": "Satisfied customer", "body": "Good product overall. Fast delivery and works as expected. Would recommend.", "verified": True},
        {"rating": 2, "title": "Not great", "body": "Product arrived late and quality is not as good as shown in pictures. Disappointed.", "verified": True},
        {"rating": 5, "title": "Fantastic!", "body": "Absolutely love this product! Great value, amazing quality. Will buy again.", "verified": True},
        {"rating": 4, "title": "Recommended", "body": "Good purchase. Product works well and shipping was quick. Happy customer.", "verified": True},
        {"rating": 3, "title": "Just okay", "body": "Product is just okay. Not bad but not great either. Expected better quality.", "verified": False},
        {"rating": 5, "title": "Perfect gift", "body": "Bought this as a gift and they loved it! Great quality and beautiful packaging.", "verified": True},
    ]
    return dummy_reviews


def fetch_product_reviews(asin: str, amazon_domain: str = "amazon.com") -> Optional[List[dict]]:
    """ì œí’ˆ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸° (ë”ë¯¸ ë°ì´í„° ëª¨ë“œ)"""
    
    REVIEWS_CACHE_FILE = "amazon_reviews_cache.json"
    
    cache_key = f"{amazon_domain}_{asin}_reviews"
    
    # ìºì‹œ í™•ì¸
    if os.path.exists(REVIEWS_CACHE_FILE):
        try:
            with open(REVIEWS_CACHE_FILE, "r", encoding="utf-8") as f:
                cache = json.load(f)
        except Exception:
            cache = {}
    else:
        cache = {}
    
    if cache_key in cache:
        st.info("âœ… ë¦¬ë·° ìºì‹œì—ì„œ ë¡œë“œ!")
        return cache[cache_key]
    
    # ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
    st.info(f"ğŸ”„ ë”ë¯¸ ë¦¬ë·° ë°ì´í„° ë¡œë“œ ì¤‘... (ASIN: {asin})")
    
    try:
        reviews = get_dummy_reviews()
        
        # ìºì‹œ ì €ì¥
        cache[cache_key] = reviews
        with open(REVIEWS_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
        
        st.success(f"âœ… {len(reviews)}ê°œ ë¦¬ë·° ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
        return reviews
    
    except Exception as e:
        st.error(f"âŒ ë¦¬ë·° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None


def summarize_reviews(reviews: List[dict]) -> dict:
    """ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ (ìˆ˜ì¶œ ê¸°ì—… ëŒ€ì‘ìš©)"""
    
    if not reviews:
        return {
            "positive": ["ë°ì´í„° ì—†ìŒ"],
            "negative": ["ë°ì´í„° ì—†ìŒ"],
            "summary": "ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    
    high_rated = [r for r in reviews if r.get('rating', 0) >= 4]
    low_rated = [r for r in reviews if r.get('rating', 0) <= 2]
    
    positive_keywords = {}
    negative_keywords = {}
    
    positive_words = ['great', 'good', 'excellent', 'love', 'best', 'perfect', 'amazing', 'works', 'warm', 'hot', 'last', 'long']
    negative_words = ['bad', 'poor', 'worst', 'terrible', 'not', 'don\'t', 'cold', 'short', 'leak', 'broke', 'waste']
    
    for review in high_rated:
        body = (review.get('body') or '').lower()
        for word in positive_words:
            if word in body:
                positive_keywords[word] = positive_keywords.get(word, 0) + 1
    
    for review in low_rated:
        body = (review.get('body') or '').lower()
        for word in negative_words:
            if word in body:
                negative_keywords[word] = negative_keywords.get(word, 0) + 1
    
    top_positive = sorted(positive_keywords.items(), key=lambda x: x[1], reverse=True)[:5]
    top_negative = sorted(negative_keywords.items(), key=lambda x: x[1], reverse=True)[:5]
    
    positive_insights = []
    negative_insights = []
    
    if top_positive:
        positive_insights = [f"'{word}' ì–¸ê¸‰ {count}íšŒ" for word, count in top_positive]
    else:
        positive_insights = ["ê¸ì •ì ì¸ ë¦¬ë·° í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    if top_negative:
        negative_insights = [f"'{word}' ì–¸ê¸‰ {count}íšŒ" for word, count in top_negative]
    else:
        negative_insights = ["ë¶€ì •ì ì¸ ë¦¬ë·°ê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤."]
    
    total = len(reviews)
    high_pct = len(high_rated) / total * 100 if total > 0 else 0
    low_pct = len(low_rated) / total * 100 if total > 0 else 0

    return {
        "positive": positive_insights,
        "negative": negative_insights,
        "summary": f"ì´ {total}ê°œ ë¦¬ë·° ë¶„ì„: í˜„ì§€ ë§Œì¡±ë„ {high_pct:.0f}% ìˆ˜ì¤€",
        "high_rated_count": len(high_rated),
        "low_rated_count": len(low_rated),
    }


def get_amazon_cache_info() -> Dict[str, int]:
    if not os.path.exists(AMAZON_CACHE_FILE):
        return {"count": 0}
    
    try:
        with open(AMAZON_CACHE_FILE, "r", encoding="utf-8") as f:
            cache = json.load(f)
            return {"count": len(cache)}
    except Exception:
        return {"count": 0}


def clear_amazon_cache() -> bool:
    try:
        if os.path.exists(AMAZON_CACHE_FILE):
            os.remove(AMAZON_CACHE_FILE)
        return True
    except Exception:
        return False



# ==================== ì•„ë§ˆì¡´ ê²½ìŸì‚¬ ë¶„ì„ ì„¹ì…˜ ====================

def render_amazon_research(key_prefix: str = "amazon") -> None:
    """STEP 2: ì•„ë§ˆì¡´ ì‹¤ì‹œê°„ ê°€ê²© ì¡°ì‚¬"""
    
    def k(name: str) -> str:
        return f"{key_prefix}_{name}"
    
    st.markdown("## ì•„ë§ˆì¡´ ì‹¤ì‹œê°„ ë§ˆì¼“ í„ìŠ¤")
    
    if k("search_query") not in st.session_state:
        st.session_state[k("search_query")] = ""
    if k("amazon_domain") not in st.session_state:
        st.session_state[k("amazon_domain")] = "amazon.com"
    if k("results") not in st.session_state:
        st.session_state[k("results")] = None
    
    col1, col2, col3 = st.columns([3, 1, 1])
    
    with col1:
        search_query = st.text_input(
            "ì•„ë§ˆì¡´ ê²€ìƒ‰ì–´ ì…ë ¥",
            key=k("search_query"),
            placeholder="ì˜ˆ: hand warmer, shampoo 500ml, cosmetic set",
            help="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì œí’ˆëª…ì„ ì˜ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”"
        )
    
    with col2:
        amazon_domain = st.selectbox(
            "ì•„ë§ˆì¡´ ë„ë©”ì¸",
            ["amazon.com", "amazon.co.uk", "amazon.de", "amazon.co.jp"],
            key=k("amazon_domain")
        )

        country_tips = {
            "amazon.com": "ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ìˆ˜ì¶œ ì‹œ FDA ì‹œì„¤ ë“±ë¡ ë° ì„±ë¶„ ê²€í† ê°€ ìµœìš°ì„ ì…ë‹ˆë‹¤.",
            "amazon.co.jp": "ğŸ‡¯ğŸ‡µ ì¼ë³¸ ìˆ˜ì¶œ ì‹œ 'ì˜ì•½ì™¸í’ˆ(Quasi-drugs)' ë¶„ë¥˜ ì—¬ë¶€ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.",
            "amazon.co.uk": "ğŸ‡¬ğŸ‡§ ì˜êµ­ ìˆ˜ì¶œ ì‹œ ìœ í†µê¸°í•œ ë° ì±…ì„ì(RP) ì§€ì •ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.",
            "amazon.de": "ğŸ‡©ğŸ‡ª ë…ì¼ ìˆ˜ì¶œ ì‹œ í™˜ê²½ ë¶€ë‹´ê¸ˆ(EPR) ë° ì¸ì¦ ë§ˆí¬ íšë“ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
        }

        st.caption(country_tips.get(amazon_domain, ""))
    
    with col3:
        st.markdown("<br>", unsafe_allow_html=True)
        search_btn = st.button("ğŸ” ê²€ìƒ‰", use_container_width=True, key=k("search_btn"))
    
    with st.expander("ì•„ë§ˆì¡´ ìºì‹œ ê´€ë¦¬"):
        cache_info = get_amazon_cache_info()
        st.metric("ì €ì¥ëœ ê²€ìƒ‰ì–´", f"{cache_info['count']}ê°œ")
        st.caption(f"ìºì‹œ íŒŒì¼: `{AMAZON_CACHE_FILE}`")
        
        if st.button("ğŸ—‘ï¸ ì•„ë§ˆì¡´ ìºì‹œ ì‚­ì œ", key=k("clear_cache")):
            if clear_amazon_cache():
                st.success("ì•„ë§ˆì¡´ ìºì‹œ ì‚­ì œ ì™„ë£Œ!")
                st.rerun()
    
    if search_btn:
        if not search_query:
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        with st.spinner("ğŸ”„ ì•„ë§ˆì¡´ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
            results = fetch_amazon_market_data(search_query, amazon_domain)
            st.session_state[k("results")] = results
    
    results = st.session_state.get(k("results"))
    
    if not results:
        st.info("ğŸ’¡ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³  'ê²€ìƒ‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        return
    
    st.markdown("---")
    
    # âœ… ìˆ˜ì •: ì‹¤ì‹œê°„ ê°€ê²© ì§€í‘œì™€ ê°€ê²©ëŒ€ ë¶„í¬ë¥¼ í†µí•©
    st.markdown("### ğŸ’° ì•„ë§ˆì¡´ ì‹¤ì‹œê°„ ê°€ê²© ë¶„ì„")
    
    prices = [r["ê°€ê²©"] for r in results if r["ê°€ê²©"] is not None]
    ratings = [r["ë³„ì "] for r in results if r["ë³„ì "] is not None]
    
    if prices:
        avg_price = sum(prices) / len(prices)
        max_price = max(prices)
        min_price = min(prices)
    else:
        avg_price = max_price = min_price = 0
    
    if ratings:
        avg_rating = sum(ratings) / len(ratings)
    else:
        avg_rating = 0
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("í‰ê·  ê°€ê²©", f"${avg_price:.2f}")
    col2.metric("ìµœê³ ê°€", f"${max_price:.2f}")
    col3.metric("ìµœì €ê°€", f"${min_price:.2f}")
    col4.metric("í‰ê·  ë³„ì ", f"{avg_rating:.1f} â­")
    
    # âœ… ê°€ê²©ëŒ€ ë¶„í¬ ì°¨íŠ¸ ì¶”ê°€
    if prices:
        st.markdown("#### ê°€ê²©ëŒ€ ë¶„í¬ (Top 15)")
        df_results = pd.DataFrame(results)
        
        min_p = min(prices)
        max_p = max(prices)
        range_p = max_p - min_p
        
        bins = []
        bin_size = range_p / 5
        for i in range(5):
            low = min_p + (i * bin_size)
            high = min_p + ((i + 1) * bin_size)
            bins.append(f"${low:.0f}-${high:.0f}")
        
        price_dist = {bin_name: 0 for bin_name in bins}
        
        for price in prices:
            idx = min(int((price - min_p) / bin_size), 4)
            bin_name = bins[idx]
            price_dist[bin_name] += 1
        
        fig_price = go.Figure(data=[
            go.Bar(
                x=list(price_dist.keys()),
                y=list(price_dist.values()),
                marker=dict(
                    color='rgba(139, 92, 246, 0.8)',
                    line=dict(width=0)
                ),
                text=list(price_dist.values()),
                textposition='outside',
                width=0.4,
            )
        ])
        fig_price.update_layout(
            xaxis_title="ê°€ê²©ëŒ€",
            yaxis_title="ì œí’ˆ ìˆ˜",
            height=350,
            showlegend=False,
            yaxis=dict(
                showgrid=True, 
                gridcolor='rgba(128, 128, 128, 0.2)',
                range=[0, max(price_dist.values()) * 1.15]
            ),
            margin=dict(t=20, b=60, l=60, r=40)
        )
        st.plotly_chart(fig_price, use_container_width=True)
        
        most_common_price = max(price_dist, key=price_dist.get)
        st.info(f"**í•µì‹¬ ì¸ì‚¬ì´íŠ¸**: ê°€ì¥ ë§ì€ ì œí’ˆì´ **{most_common_price}** ê°€ê²©ëŒ€ì— ìœ„ì¹˜")
    
    st.markdown("---")
    
    # ğŸ† ê²½ìŸì‚¬ Top 15 í…Œì´ë¸”
    st.markdown("### ğŸ† ê²½ìŸì‚¬ Top 15 ì œí’ˆ ëª©ë¡")
    
    df_results = pd.DataFrame(results)
    df_results.insert(0, "ìˆœìœ„", range(1, len(df_results) + 1))
    
    df_results["Amazon ë§í¬"] = df_results.apply(
        lambda row: f"https://www.amazon.com/dp/{row['asin']}" if row.get('asin') else "", 
        axis=1
    )
    
    df_results["ê°€ê²©_í‘œì‹œ"] = df_results["ê°€ê²©"].apply(lambda x: f"${x:.2f}" if x else "N/A")
    
    display_df = df_results[["ìˆœìœ„", "ì œí’ˆëª…", "ê°€ê²©_í‘œì‹œ", "ë³„ì ", "ë¦¬ë·°ìˆ˜"]].copy()
    display_df.columns = ["ìˆœìœ„", "ì œí’ˆëª…", "ê°€ê²©", "ë³„ì ", "ë¦¬ë·°ìˆ˜"]
    
    st.dataframe(
        display_df,
        use_container_width=True,
        height=550,
        hide_index=True,
        column_config={
            "ìˆœìœ„": st.column_config.NumberColumn("ìˆœìœ„", width="small"),
            "ì œí’ˆëª…": st.column_config.TextColumn("ì œí’ˆëª…", width="large"),
            "ê°€ê²©": st.column_config.TextColumn("ê°€ê²©", width="small"),
            "ë³„ì ": st.column_config.NumberColumn("ë³„ì ", format="%.1f â­", width="small"),
            "ë¦¬ë·°ìˆ˜": st.column_config.NumberColumn("ë¦¬ë·°ìˆ˜", format="%d", width="small"),
        }
    )
    
    # ê²½ìŸ êµ¬ë„ ë¶„ì„
    if results:
        df_results = pd.DataFrame(results)
        
        st.markdown("### ğŸ“Š ì‹œì¥ ê²½ìŸ êµ¬ë„ ë¶„ì„(Top 15)")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ê²½ìŸì‚¬ ê°€ê²©ëŒ€ ë¶„í¬")
            
            # ê°€ê²© ë°ì´í„° ì¶”ì¶œ
            chart_prices = [r['ê°€ê²©'] for r in results if r.get('ê°€ê²©') and r['ê°€ê²©'] > 0]
            
            if chart_prices:
                # íˆìŠ¤í† ê·¸ë¨ ìƒì„±
                fig_hist = px.histogram(
                    x=chart_prices,
                    nbins=8,
                    color_discrete_sequence=['#22c55e']
                )
                fig_hist.update_layout(
                    xaxis_title="ê°€ê²© ($)",
                    yaxis_title="count",
                    height=400,
                    showlegend=False,
                    bargap=0.1,
                    margin=dict(t=20, b=60, l=60, r=40)
                )
                fig_hist.update_traces(
                    marker_line_width=0,
                    opacity=0.9
                )
                st.plotly_chart(fig_hist, use_container_width=True)
            else:
                st.warning("ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.markdown("#### ì£¼ìš” ë¸Œëœë“œ ì ìœ ìœ¨")

            if 'ë¸Œëœë“œ' in df_results.columns:
                brand_counts = df_results['ë¸Œëœë“œ'].value_counts().head(5)
                fig_brand = px.pie(values=brand_counts.values, 
                                    names=brand_counts.index, 
                                    hole=0.4, 
                                    color_discrete_sequence=px.colors.sequential.Greens_r)
                fig_brand.update_layout(
                    height=400,
                    margin=dict(t=20, b=20, l=20, r=20)
                )
                fig_brand.update_traces(
                    textposition='inside',
                    textinfo='percent',
                    textfont_size=12
                )
                st.plotly_chart(fig_brand, use_container_width=True)
            else:
                st.warning("ë¸Œëœë“œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # Top 1 ì œí’ˆ ì „ëµ ë¶„ì„
        st.markdown("---")
        st.markdown("### ğŸ“ Champion Analysis: 1ìœ„ ì œí’ˆ ì •ë³µ ê°€ì´ë“œ")
        top_product = results[0]
        
        with st.expander(f"í˜„ì¬ 1ìœ„ ì œí’ˆ: {top_product['ì œí’ˆëª…'][:60]}...", expanded=True):
            if st.button("ì „ëµì  ìƒì„¸ ë¶„ì„ ì‹¤í–‰"):
                with st.spinner("ë‹¨ê°€ ë° ìˆ˜ì¶œ ì§„ì¶œ ì „ëµì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    analysis_data = summarize_description_backup(
                        top_product['asin'], 
                        top_product['ì œí’ˆëª…'], 
                        top_product['ê°€ê²©']
                    )

                    reviews = fetch_product_reviews(top_product['asin'])

                    st.markdown("#### ì‹¤ì‹œê°„ ì œí’ˆêµ¬ì„± ë° ë‹¨ê°€ ë¶„ì„")
                    col_q, col_p = st.columns(2)
                    col_q.metric("ì¶”ì¶œëœ ìˆ˜ëŸ‰", f"{analysis_data['qty']} ê°œì…")
                    col_p.metric("ê°œë‹¹ ê°€ê²©", f"${analysis_data['unit_price']:.2f}")
                    st.markdown("---")

                    if reviews:
                        summary = summarize_reviews(reviews)
                      
                                            
                    st.success(analysis_data['analysis'])

    with st.expander("ì œí’ˆ ë§í¬ ë³´ê¸°"):
        for idx, row in df_results.iterrows():
            if row.get("asin"):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.text(f"{idx + 1}. {row['ì œí’ˆëª…'][:80]}...") 
                with col2:
                    st.link_button("ìƒí’ˆ í˜ì´ì§€", f"https://www.amazon.com/dp/{row['asin']}", use_container_width=True)


# ==================== ë©”ì¸ ì‹¤í–‰ ====================

def main():
    st.set_page_config(
        page_title="SY ê¸€ë¡œë²Œ ì»¤ë„¥íŠ¸",
        page_icon="ğŸš€",
        layout="wide",
    )

    # ==================== ğŸ”½ ì—¬ê¸°ì— ì‚¬ì´ë“œë°” ì½”ë“œ ì‚½ì…! ====================
    import base64
    
    # ì‚¬ì´ë“œë°” CSS
    st.markdown("""
        <style>
        [data-testid="stSidebarNav"] { display: none; }
        section[data-testid="stSidebar"] { 
            background: #ffffff !important;
            border-right: 1px solid #e5e7eb;
        }
        .stButton>button {
            background: #051161 !important;
            color: #ffffff !important;
            border: none !important;
            border-radius: 8px;
            padding: 10px 14px;
            font-weight: 700;
            transition: 0.3s;
        }
        .stButton>button:hover {
            background: rgba(5,17,97,0.85) !important;
            box-shadow: 0 4px 12px rgba(5,17,97,0.3) !important;
        }
        .logo-box{
            background: rgba(255,255,255,0.6);
            border: 1px solid #e5e7eb;
            border-radius: 14px;
            padding: 14px 12px;
            margin-bottom: 10px;
            text-align:center;
        }
        .logo-img{
            max-width: 150px;
            width: 100%;
            height: auto;
            display:block;
            margin: 0 auto;
        }
        .small-muted{
            color:#64748b;
            font-size: 0.85rem;
            font-weight: 600;
            letter-spacing: 0.2px;
        }
        </style>
    """, unsafe_allow_html=True)
    
    with st.sidebar: 
        # 1) êµ­ê°€ë³„ ìˆ˜ì¶œì… ë°ì´í„°
        with st.expander("1) í•´ì™¸ì§„ì¶œ ì „ëµ í—ˆë¸Œ", expanded=False):
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("ì‹œì¥ë™í–¥", use_container_width=True, key="nav_cn_1"):
                    st.switch_page("pages/macro_1.py")
            with col2:
                if st.button("ì „ëµë¶„ì„", use_container_width=True, key="nav_cn_2"):
                    st.switch_page("pages/micro_1.py")
            with col3:
                if st.button("ê·œì œì§„ë‹¨", use_container_width=True, key="nav_cn_3"):
                    st.switch_page("pages/mac_mic_1.py")

        # 2) SEO ì„œë¹„ìŠ¤
        with st.expander("2) SEO ì„œë¹„ìŠ¤", expanded=False):
            if st.button("ë°”ë¡œê°€ê¸°", use_container_width=True, key="nav_news"):
                st.switch_page("pages/junghyun.py")

        # 3) AI ë°”ì´ì–´ ë§¤ì¹­ ì„œë¹„ìŠ¤
        with st.expander("3) AI ë°”ì´ì–´ ë§¤ì¹­ ì„œë¹„ìŠ¤", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ë°”ì´ì–´ ì°¾ê¸°", use_container_width=True, key="nav_ai_1"):
                    st.switch_page("pages/03_ai_chatbot.py")
            with col2:
                if st.button("ì „ì‹œíšŒ ì¼ì •", use_container_width=True, key="nav_ai_2"):
                    st.switch_page("pages/buyer_maps.py")        

        # 4) í™˜ìœ¨ ì •ë³´ í™•ì¸
        with st.expander("4) í™˜ìœ¨ ì •ë³´ í™•ì¸", expanded=False):
            if st.button("ë°”ë¡œê°€ê¸°", use_container_width=True, key="nav_ex"):
                st.switch_page("pages/exchange_rate.py")

         # 5) ë¬´ì—­ ì„œë¥˜ ìë™ ì™„ì„±
        with st.expander("5) ë¬´ì—­ ì„œë¥˜ ìë™ ì™„ì„±", expanded=False):
            if st.button("ë°”ë¡œê°€ê¸°", use_container_width=True, key="nav_fx"):
                st.switch_page("pages/auto_docs.py")


        # ë¡œê³  ì˜ì—­
        logo_path = "assets/logo.png"
        if os.path.exists(logo_path):
            logo_b64 = base64.b64encode(open(logo_path, "rb").read()).decode()
            st.markdown(
                f"""
                <div class="logo-box">
                  <img class="logo-img" src="data:image/png;base64,{logo_b64}" alt="logo"/>
                  <div class="small-muted" style="margin-top:8px; text-align:center;">
                    KITA AX MASTER TEAM4
                  </div>
                </div>
                """,
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                """
                <div class="logo-box">
                  <div style="font-size:1.15rem; font-weight:900; color:#0f172a;">ğŸš€ SEO Suite</div>
                  <div class="small-muted" style="margin-top:6px;">KITA AX MASTER TEAM4</div>
                </div>
                """,
                unsafe_allow_html=True,
            )

        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("---")

        # í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°
        if st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True, key="go_home_sidebar"):
            st.switch_page("dashboard.py")
    

    st.markdown("""
    <style>
    .block-container{ padding-top: 2rem; }
    </style>
    """, unsafe_allow_html=True)

    # 1. ìµœìƒìœ„ í†µí•© ì¹´í…Œê³ ë¦¬ íƒ€ì´í‹€ ì¶”ê°€
    st.markdown("# ğŸš¢ í•´ì™¸ì§„ì¶œ ì „ëµ í—ˆë¸Œ")
    
    # 2. êµ¬ë¶„ì„ 
    st.markdown("---")
    
    # 3. ë¯¸ì‹œì  ë¶„ì„ ì„¹ì…˜ í˜¸ì¶œ (ì´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ 'Micro Dynamics' ì œëª©ì´ ë‚˜ì˜µë‹ˆë‹¤)
    render_amazon_research(key_prefix="amazon")

if __name__ == "__main__":
    main()

# --- Footer ---
st.divider()
st.markdown("""
<div style='text-align: center; color: #718096; font-size: 0.9em;'>
    <p>Global E-commerce All In One Solution</p>
    <p>Developed by Seyeon Global Connect</p>
</div>
""", unsafe_allow_html=True)